{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"rustac","text":"<p>The power of Rust for the Python STAC ecosystem.</p> <p>Tip</p> <p>We pronounce rustac \"ruh-stac\"</p> <p>Note</p> <p>Until 2025-04-17, this package was named stacrs. See this RFC for context on the name change.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>python -m pip install rustac\n</code></pre> <p>If you'd like to use <code>arrow</code> tables, e.g. to load into GeoPandas:</p> <pre><code>python -m pip install 'rustac[arrow]'\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<pre><code>import asyncio\nimport rustac\n\ndef main() -&gt; None:\n    item = await rustac.read(\"item.json\")\n\nasyncio.run(main())\n</code></pre> <p>For more, see our examples.</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>We'd like to thank @jkeifer, @parksjr, and @Xenocide122 (all from @Element84) for creating the rustac logo from an AI-generated image from this prompt:</p> <p>There is a library for working with STAC metadata that is written in rust called rustac: https://github.com/stac-utils/rustac. That name sounds like the word \"rustic\", and is meant to envoke (sic) an image of \"a cabin and a glass of neat whisky\".</p>"},{"location":"CONTRIBUTING/","title":"Contributing","text":"<p>First off, thanks for contributing! We appreciates you.</p>"},{"location":"CONTRIBUTING/#relationship-to-stac-utilsrustac","title":"Relationship to stac-utils/rustac","text":"<p>stac-utils/rustac is a Rust monorepo that provides most of the functionality of this Python package. It's pretty common that a bug in rustac-py is actually a bug in rustac. Knowing which repository to work in can be a little tricky, so don't hesitate to reach out and ask.</p>"},{"location":"CONTRIBUTING/#python-environment","title":"Python environment","text":"<p>It can be a little tricky to ensure that your Python environment is always up-to-date while developing a Rust+Python project. We're still figuring out the best way, but for now, try this:</p> <pre><code>uv sync\npython -m maturin_import_hook site install\n</code></pre> <p>This should make sure your pytest runs are picking up the latest changes to your Rust code.</p>"},{"location":"CONTRIBUTING/#testing","title":"Testing","text":"<p>We aim for comprehensive unit testing of this library. Please provide tests for any new features, or to demonstrate bugs. Draft pull requests with a failing test to demonstrate a bug are much appreciated.</p>"},{"location":"CONTRIBUTING/#submitting-changes","title":"Submitting changes","text":"<p>Please open a pull request with your changes -- make sure to include unit tests. Please follow standard git commit formatting (subject line 50 characters max, wrap the body at 72 characters).</p> <p>We use conventional commits. Your commits do not have to but if you'd like to format them this way, we would be grateful.</p> <p>If you can, use <code>git rebase -i</code> to create a clean, well-formatted history before opening your pull request. If you need to make changes after opening your pull request (e.g. to fix CI breakages) we will be grateful if you squash those fixes into their relevant commits.</p> <p>Thanks so much!</p> <p>-Pete Gadomski</p>"},{"location":"api/","title":"API","text":"<p>API documentation for the rustac Python package.</p>"},{"location":"api/#format","title":"Format","text":"<p>Several functions, including rustac.write, take a <code>format</code> argument. Valid values are:</p> <ul> <li><code>json</code> or <code>geojson</code>: compact (no whitespace) JSON</li> <li><code>json-pretty</code> or <code>geojson-pretty</code>: indented JSON</li> <li><code>ndjson</code>: newline-delimited JSON (also known as <code>geojson-seq</code>)</li> <li><code>parquet</code> or <code>geoparquet</code>: uncompressed geoparquet</li> <li><code>parquet[{compression}]</code> or <code>geoparquet[{compression}]</code>: compressed parquet, where valid values for <code>compression</code> are the lowercase string versions of the values enumerated in stac::geoparquet::Compression.</li> </ul> <p>Tip</p> <p>If you're not sure which geoparquet compression to use, we suggest <code>parquet[snappy]</code></p> <p>Note</p> <p>The distinction between pretty and compact JSON, or compressed and uncompressed geoparquet, is only relevant on write. On read, the formats are treated the same.</p> <p>Under the hood, the <code>format</code> argument is parsed into a Format enum.</p>"},{"location":"api/arrow/","title":"Arrow","text":"<p>These functions require the <code>arrow</code> extra, e.g.:</p> <pre><code>python -m pip install 'rustac[arrow]'\n</code></pre>"},{"location":"api/arrow/#rustac.to_arrow","title":"rustac.to_arrow","text":"<pre><code>to_arrow(items: list[Item] | ItemCollection) -&gt; Table\n</code></pre> <p>Converts items to an arro3.core.Table.</p> <p>Requires rustac to be installed with the <code>arrow</code> extra.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>list[Item] | ItemCollection</code>)           \u2013            <p>Either a list of items or a item collection</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>The table</p> </li> </ul>"},{"location":"api/arrow/#rustac.from_arrow","title":"rustac.from_arrow","text":"<pre><code>from_arrow(table: Table) -&gt; ItemCollection\n</code></pre> <p>Converts an arro3.core.Table to a STAC item collection.</p> <p>Requires rustac to be installed with the <code>arrow</code> extra.</p> <p>Parameters:</p> <ul> <li> <code>table</code>               (<code>Table</code>)           \u2013            <p>The table</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ItemCollection</code>           \u2013            <p>The STAC item collection</p> </li> </ul>"},{"location":"api/duckdb/","title":"DuckDB","text":""},{"location":"api/duckdb/#rustac.DuckdbClient","title":"rustac.DuckdbClient","text":"<p>A client for querying stac-geoparquet with DuckDB.</p>"},{"location":"api/duckdb/#rustac.DuckdbClient.__init__","title":"__init__","text":"<pre><code>__init__(\n    *,\n    extension_directory: Path | None = None,\n    extensions: list[str] | None = None,\n    install_extensions: bool = True,\n    use_hive_partitioning: bool = False,\n) -&gt; None\n</code></pre> <p>Creates a new duckdb client.</p> <p>Parameters:</p> <ul> <li> <code>extension_directory</code>               (<code>Path | None</code>, default:                   <code>None</code> )           \u2013            <p>A non-standard extension directory to use.</p> </li> <li> <code>extensions</code>               (<code>list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>A list of extensions to LOAD on client initialization.</p> </li> <li> <code>install_extensions</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to install the required extensions on client initialization.</p> </li> <li> <code>use_hive_partitioning</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use hive partitioning for geoparquet queries.</p> </li> </ul>"},{"location":"api/duckdb/#rustac.DuckdbClient.execute","title":"execute","text":"<pre><code>execute(sql: str, params: list[str] | None = None) -&gt; int\n</code></pre> <p>Execute an SQL command.</p> <p>This can be useful for configuring AWS credentials, for example.</p> <p>Parameters:</p> <ul> <li> <code>sql</code>               (<code>str</code>)           \u2013            <p>The SQL to execute</p> </li> <li> <code>params</code>               (<code>list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>The parameters to pass in to the execution</p> </li> </ul>"},{"location":"api/duckdb/#rustac.DuckdbClient.get_collections","title":"get_collections","text":"<pre><code>get_collections(href: str) -&gt; list[Collection]\n</code></pre> <p>Returns all collections in this stac-geoparquet file.</p> <p>These collections will be auto-generated from the STAC items, one collection per id in the <code>collections</code> column.</p> <p>Eventually, these collections might be stored in the stac-geoparquet metadata and retrieved from there, but that's not the case yet.</p> <p>Parameters:</p> <ul> <li> <code>href</code>               (<code>str</code>)           \u2013            <p>The stac-geoparquet file to build the collections from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Collection]</code>           \u2013            <p>A list of STAC Collections</p> </li> </ul>"},{"location":"api/duckdb/#rustac.DuckdbClient.search","title":"search","text":"<pre><code>search(\n    href: str,\n    *,\n    ids: str | list[str] | None = None,\n    collections: str | list[str] | None = None,\n    intersects: str | dict[str, Any] | None = None,\n    limit: int | None = None,\n    offset: int | None = None,\n    bbox: list[float] | None = None,\n    datetime: str | None = None,\n    include: str | list[str] | None = None,\n    exclude: str | list[str] | None = None,\n    sortby: str | list[str | dict[str, str]] | None = None,\n    filter: str | dict[str, Any] | None = None,\n    query: dict[str, Any] | None = None,\n    **kwargs: str,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Search a stac-geoparquet file with duckdb, returning a list of items.</p> <p>Parameters:</p> <ul> <li> <code>href</code>               (<code>str</code>)           \u2013            <p>The stac-geoparquet file.</p> </li> <li> <code>ids</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Array of Item ids to return.</p> </li> <li> <code>collections</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Array of one or more Collection IDs that each matching Item must be in.</p> </li> <li> <code>intersects</code>               (<code>str | dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Searches items by performing intersection between their geometry and provided GeoJSON geometry.</p> </li> <li> <code>limit</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of items to return.</p> </li> <li> <code>offset</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of items to skip before returning.</p> </li> <li> <code>bbox</code>               (<code>list[float] | None</code>, default:                   <code>None</code> )           \u2013            <p>Requested bounding box.</p> </li> <li> <code>datetime</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Single date+time, or a range (<code>/</code> separator), formatted to RFC 3339, section 5.6.  Use double dots .. for open date ranges.</p> </li> <li> <code>include</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>fields to include in the response (see the extension docs) for more on the semantics).</p> </li> <li> <code>exclude</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>fields to exclude from the response (see the extension docs) for more on the semantics).</p> </li> <li> <code>sortby</code>               (<code>str | list[str | dict[str, str]] | None</code>, default:                   <code>None</code> )           \u2013            <p>Fields by which to sort results (use <code>-field</code> to sort descending).</p> </li> <li> <code>filter</code>               (<code>str | dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>CQL2 filter expression. Strings will be interpreted as cql2-text, dictionaries as cql2-json.</p> </li> <li> <code>query</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional filtering based on properties.  It is recommended to use filter instead, if possible.</p> </li> <li> <code>kwargs</code>               (<code>str</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters to pass in to the search.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of STAC items.</p> </li> </ul>"},{"location":"api/duckdb/#rustac.DuckdbClient.search_to_arrow","title":"search_to_arrow","text":"<pre><code>search_to_arrow(\n    href: str,\n    *,\n    ids: str | list[str] | None = None,\n    collections: str | list[str] | None = None,\n    intersects: str | dict[str, Any] | None = None,\n    limit: int | None = None,\n    offset: int | None = None,\n    bbox: list[float] | None = None,\n    datetime: str | None = None,\n    include: str | list[str] | None = None,\n    exclude: str | list[str] | None = None,\n    sortby: str | list[str | dict[str, str]] | None = None,\n    filter: str | dict[str, Any] | None = None,\n    query: dict[str, Any] | None = None,\n    **kwargs: str,\n) -&gt; Table | None\n</code></pre> <p>Search a stac-geoparquet file with duckdb, returning an arrow table suitable for loading into (e.g.) GeoPandas.</p> <p>rustac must be installed with the <code>arrow</code> extra, e.g. `python -m pip *install 'rustac[arrow]'.</p> <p>Because DuckDB has arrow as a core output format, this can be more performant than going through a JSON dictionary.</p> <p>Parameters:</p> <ul> <li> <code>href</code>               (<code>str</code>)           \u2013            <p>The stac-geoparquet file.</p> </li> <li> <code>ids</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Array of Item ids to return.</p> </li> <li> <code>collections</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Array of one or more Collection IDs that each matching Item must be in.</p> </li> <li> <code>intersects</code>               (<code>str | dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Searches items by performing intersection between their geometry and provided GeoJSON geometry.</p> </li> <li> <code>limit</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of items to return.</p> </li> <li> <code>offset</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of items to skip before returning.</p> </li> <li> <code>bbox</code>               (<code>list[float] | None</code>, default:                   <code>None</code> )           \u2013            <p>Requested bounding box.</p> </li> <li> <code>datetime</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Single date+time, or a range (<code>/</code> separator), formatted to RFC 3339, section 5.6.  Use double dots .. for open date ranges.</p> </li> <li> <code>include</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>fields to include in the response (see the extension docs) for more on the semantics).</p> </li> <li> <code>exclude</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>fields to exclude from the response (see the extension docs) for more on the semantics).</p> </li> <li> <code>sortby</code>               (<code>str | list[str | dict[str, str]] | None</code>, default:                   <code>None</code> )           \u2013            <p>Fields by which to sort results (use <code>-field</code> to sort descending).</p> </li> <li> <code>filter</code>               (<code>str | dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>CQL2 filter expression. Strings will be interpreted as cql2-text, dictionaries as cql2-json.</p> </li> <li> <code>query</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional filtering based on properties.  It is recommended to use filter instead, if possible.</p> </li> <li> <code>kwargs</code>               (<code>str</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters to pass in to the search.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table | None</code>           \u2013            <p>An arrow table, or none if no records were returned.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; table = client.search_to_arrow(\"data/100-sentinel-2-items.parquet\")\n&gt;&gt;&gt; data_frame = GeoDataFrame.from_arrow(table)\n</code></pre>"},{"location":"api/migrate/","title":"Migration","text":""},{"location":"api/migrate/#rustac.migrate","title":"rustac.migrate","text":"<pre><code>migrate(value: dict[str, Any], version: str | None = None) -&gt; dict[str, Any]\n</code></pre> <p>Migrates a STAC dictionary to another version.</p> <p>Migration can be as simple as updating the <code>stac_version</code> attribute, but sometimes can be more complicated. For example, when migrating to v1.1.0, eo:bands and raster:bands should be consolidated to the new bands structure.</p> <p>See the rustac documentation for supported versions.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>dict[str, Any]</code>)           \u2013            <p>The STAC value to migrate</p> </li> <li> <code>version</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The version to migrate to. If not provided, the value will be migrated to the latest stable version.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[str, Any]</code>           \u2013            <p>The migrated dictionary</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; with open(\"examples/simple-item.json\") as f:\n&gt;&gt;&gt;     item = json.load(f)\n&gt;&gt;&gt; item = rustac.migrate(item, \"1.1.0-beta.1\")\n&gt;&gt;&gt; assert item[\"stac_version\"] == \"1.1.0-beta.1\"\n</code></pre>"},{"location":"api/read/","title":"Read","text":""},{"location":"api/read/#rustac.read","title":"rustac.read  <code>async</code>","text":"<pre><code>read(\n    href: str,\n    *,\n    format: str | None = None,\n    store: AnyObjectStore | None = None,\n    set_self_link: bool = True,\n) -&gt; dict[str, Any]\n</code></pre> <p>Reads STAC from a href.</p> <p>Parameters:</p> <ul> <li> <code>href</code>               (<code>str</code>)           \u2013            <p>The href to write to</p> </li> <li> <code>format</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The input format. If not provided, will be inferred from the href's extension.</p> </li> <li> <code>store</code>               (<code>AnyObjectStore | None</code>, default:                   <code>None</code> )           \u2013            <p>An optional [ObjectStore][]</p> </li> <li> <code>set_self_link</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, set the <code>self</code> link to the value of <code>href</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[str, Any]</code>           \u2013            <p>The STAC value</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; item = await rustac.read(\"item.json\")\n</code></pre>"},{"location":"api/search/","title":"Search","text":""},{"location":"api/search/#rustac.search","title":"rustac.search  <code>async</code>","text":"<pre><code>search(\n    href: str,\n    *,\n    intersects: str | dict[str, Any] | None = None,\n    ids: str | list[str] | None = None,\n    collections: str | list[str] | None = None,\n    max_items: int | None = None,\n    limit: int | None = None,\n    bbox: list[float] | None = None,\n    datetime: str | None = None,\n    include: str | list[str] | None = None,\n    exclude: str | list[str] | None = None,\n    sortby: str | list[str | dict[str, str]] | None = None,\n    filter: str | dict[str, Any] | None = None,\n    query: dict[str, Any] | None = None,\n    use_duckdb: bool | None = None,\n    **kwargs: str,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Searches a STAC API server.</p> <p>Parameters:</p> <ul> <li> <code>href</code>               (<code>str</code>)           \u2013            <p>The STAC API to search.</p> </li> <li> <code>intersects</code>               (<code>str | dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Searches items by performing intersection between their geometry and provided GeoJSON geometry.</p> </li> <li> <code>ids</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Array of Item ids to return.</p> </li> <li> <code>collections</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Array of one or more Collection IDs that each matching Item must be in.</p> </li> <li> <code>max_items</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The maximum number of items to iterate through.</p> </li> <li> <code>limit</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The page size returned from the server. Use <code>max_items</code> to actually limit the number of items returned from this function.</p> </li> <li> <code>bbox</code>               (<code>list[float] | None</code>, default:                   <code>None</code> )           \u2013            <p>Requested bounding box.</p> </li> <li> <code>datetime</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Single date+time, or a range (<code>/</code> separator), formatted to RFC 3339, section 5.6.  Use double dots .. for open date ranges.</p> </li> <li> <code>include</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>fields to include in the response (see the extension docs) for more on the semantics).</p> </li> <li> <code>exclude</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>fields to exclude from the response (see the extension docs) for more on the semantics).</p> </li> <li> <code>sortby</code>               (<code>str | list[str | dict[str, str]] | None</code>, default:                   <code>None</code> )           \u2013            <p>Fields by which to sort results (use <code>-field</code> to sort descending).</p> </li> <li> <code>filter</code>               (<code>str | dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>CQL2 filter expression. Strings will be interpreted as cql2-text, dictionaries as cql2-json.</p> </li> <li> <code>query</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional filtering based on properties. It is recommended to use filter instead, if possible.</p> </li> <li> <code>use_duckdb</code>               (<code>bool | None</code>, default:                   <code>None</code> )           \u2013            <p>Query with DuckDB. If None and the href has a 'parquet' or 'geoparquet' extension, will be set to True. Defaults to None.</p> </li> <li> <code>kwargs</code>               (<code>str</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters to pass in to the search.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>STAC items</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; items = await rustac.search(\n...     \"https://landsatlook.usgs.gov/stac-server\",\n...     collections=[\"landsat-c2l2-sr\"],\n...     intersects={\"type\": \"Point\", \"coordinates\": [-105.119, 40.173]},\n...     sortby=\"-properties.datetime\",\n...     max_items=1,\n... )\n</code></pre>"},{"location":"api/search/#rustac.search_to","title":"rustac.search_to  <code>async</code>","text":"<pre><code>search_to(\n    outfile: str,\n    href: str,\n    *,\n    intersects: str | dict[str, Any] | None = None,\n    ids: str | list[str] | None = None,\n    collections: str | list[str] | None = None,\n    max_items: int | None = None,\n    limit: int | None = None,\n    bbox: list[float] | None = None,\n    datetime: str | None = None,\n    include: str | list[str] | None = None,\n    exclude: str | list[str] | None = None,\n    sortby: str | list[str | dict[str, str]] | None = None,\n    filter: str | dict[str, Any] | None = None,\n    query: dict[str, Any] | None = None,\n    format: str | None = None,\n    store: AnyObjectStore | None = None,\n    use_duckdb: bool | None = None,\n) -&gt; int\n</code></pre> <p>Searches a STAC API server and saves the result to an output file.</p> <p>Parameters:</p> <ul> <li> <code>outfile</code>               (<code>str</code>)           \u2013            <p>The output href. This can be a local file path, or any url scheme supported by [stac::object_store::write].</p> </li> <li> <code>href</code>               (<code>str</code>)           \u2013            <p>The STAC API to search.</p> </li> <li> <code>intersects</code>               (<code>str | dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Searches items by performing intersection between their geometry and provided GeoJSON geometry.</p> </li> <li> <code>ids</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Array of Item ids to return.</p> </li> <li> <code>collections</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Array of one or more Collection IDs that each matching Item must be in.</p> </li> <li> <code>max_items</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The maximum number of items to iterate through.</p> </li> <li> <code>limit</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The page size returned from the server. Use <code>max_items</code> to actually limit the number of items returned from this function.</p> </li> <li> <code>bbox</code>               (<code>list[float] | None</code>, default:                   <code>None</code> )           \u2013            <p>Requested bounding box.</p> </li> <li> <code>datetime</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Single date+time, or a range ('/' separator), formatted to RFC 3339, section 5.6.  Use double dots .. for open date ranges.</p> </li> <li> <code>include</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>fields to include in the response (see the extension docs) for more on the semantics).</p> </li> <li> <code>exclude</code>               (<code>str | list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>fields to exclude from the response (see the extension docs) for more on the semantics).</p> </li> <li> <code>sortby</code>               (<code>str | list[str | dict[str, str]] | None</code>, default:                   <code>None</code> )           \u2013            <p>Fields by which to sort results (use <code>-field</code> to sort descending).</p> </li> <li> <code>filter</code>               (<code>str | dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>CQL2 filter expression. Strings will be interpreted as cql2-text, dictionaries as cql2-json.</p> </li> <li> <code>query</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional filtering based on properties. It is recommended to use filter instead, if possible.</p> </li> <li> <code>format</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The output format. If none, will be inferred from the outfile extension, and if that fails will fall back to compact JSON.</p> </li> <li> <code>store</code>               (<code>AnyObjectStore | None</code>, default:                   <code>None</code> )           \u2013            <p>An optional [ObjectStore][]</p> </li> <li> <code>use_duckdb</code>               (<code>bool | None</code>, default:                   <code>None</code> )           \u2013            <p>Query with DuckDB. If None and the href has a 'parquet' or 'geoparquet' extension, will be set to True. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>The number of items written</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; count = await rustac.search_to(\"out.parquet\",\n...     \"https://landsatlook.usgs.gov/stac-server\",\n...     collections=[\"landsat-c2l2-sr\"],\n...     intersects={\"type\": \"Point\", \"coordinates\": [-105.119, 40.173]},\n...     sortby=\"-properties.datetime\",\n...     max_items=1,\n... )\n</code></pre>"},{"location":"api/stac/","title":"STAC","text":"<p>Typed dictionaries for STAC entities.</p>"},{"location":"api/stac/#rustac.Catalog","title":"rustac.Catalog","text":"<p>               Bases: <code>TypedDict</code></p> <p>A STAC Catalog object represents a logical group of other Catalog, Collection, and Item objects.</p>"},{"location":"api/stac/#rustac.Catalog.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: Required[str]\n</code></pre> <p>Detailed multi-line description to fully explain the Catalog.</p> <p>CommonMark 0.29 syntax MAY be used for rich text representation.</p>"},{"location":"api/stac/#rustac.Catalog.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: Required[str]\n</code></pre> <p>Identifier for the Catalog.</p>"},{"location":"api/stac/#rustac.Catalog.links","title":"links  <code>instance-attribute</code>","text":"<pre><code>links: Required[list[Link]]\n</code></pre> <p>A list of references to other documents.</p>"},{"location":"api/stac/#rustac.Catalog.stac_extensions","title":"stac_extensions  <code>instance-attribute</code>","text":"<pre><code>stac_extensions: list[str] | None\n</code></pre> <p>A list of extension identifiers the Catalog implements.</p>"},{"location":"api/stac/#rustac.Catalog.stac_version","title":"stac_version  <code>instance-attribute</code>","text":"<pre><code>stac_version: Required[str]\n</code></pre> <p>The STAC version the Catalog implements.</p>"},{"location":"api/stac/#rustac.Catalog.title","title":"title  <code>instance-attribute</code>","text":"<pre><code>title: str | None\n</code></pre> <p>A short descriptive one-line title for the Catalog.</p>"},{"location":"api/stac/#rustac.Catalog.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[str]\n</code></pre> <p>Set to Catalog if this Catalog only implements the Catalog spec.</p>"},{"location":"api/stac/#rustac.Collection","title":"rustac.Collection","text":"<p>               Bases: <code>TypedDict</code></p> <p>The STAC Collection Specification defines a set of common fields to describe a group of Items that share properties and metadata.</p>"},{"location":"api/stac/#rustac.Collection.assets","title":"assets  <code>instance-attribute</code>","text":"<pre><code>assets: dict[str, Asset] | None\n</code></pre> <p>Dictionary of asset objects that can be downloaded, each with a unique key.</p>"},{"location":"api/stac/#rustac.Collection.description","title":"description  <code>instance-attribute</code>","text":"<pre><code>description: Required[str]\n</code></pre> <p>Detailed multi-line description to fully explain the Collection.</p> <p>CommonMark 0.29 syntax MAY be used for rich text representation.</p>"},{"location":"api/stac/#rustac.Collection.extent","title":"extent  <code>instance-attribute</code>","text":"<pre><code>extent: Required[Extent]\n</code></pre> <p>Spatial and temporal extents.</p>"},{"location":"api/stac/#rustac.Collection.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: Required[str]\n</code></pre> <p>Identifier for the Collection that is unique across all collections in the root catalog.</p>"},{"location":"api/stac/#rustac.Collection.item_assets","title":"item_assets  <code>instance-attribute</code>","text":"<pre><code>item_assets: dict[str, ItemAsset] | None\n</code></pre> <p>A dictionary of assets that can be found in member Items.</p>"},{"location":"api/stac/#rustac.Collection.keywords","title":"keywords  <code>instance-attribute</code>","text":"<pre><code>keywords: list[str] | None\n</code></pre> <p>List of keywords describing the Collection.</p>"},{"location":"api/stac/#rustac.Collection.license","title":"license  <code>instance-attribute</code>","text":"<pre><code>license: Required[str]\n</code></pre> <p>License(s) of the data collection as SPDX License identifier, SPDX License expression, or <code>other</code>.</p>"},{"location":"api/stac/#rustac.Collection.links","title":"links  <code>instance-attribute</code>","text":"<pre><code>links: Required[list[Link]]\n</code></pre> <p>A list of references to other documents.</p>"},{"location":"api/stac/#rustac.Collection.providers","title":"providers  <code>instance-attribute</code>","text":"<pre><code>providers: list[Provider] | None\n</code></pre> <p>A list of providers, which may include all organizations capturing or processing the data or the hosting provider.</p>"},{"location":"api/stac/#rustac.Collection.stac_extensions","title":"stac_extensions  <code>instance-attribute</code>","text":"<pre><code>stac_extensions: list[str] | None\n</code></pre> <p>A list of extension identifiers the Collection implements.</p>"},{"location":"api/stac/#rustac.Collection.stac_version","title":"stac_version  <code>instance-attribute</code>","text":"<pre><code>stac_version: Required[str]\n</code></pre> <p>The STAC version the Collection implements.</p>"},{"location":"api/stac/#rustac.Collection.summaries","title":"summaries  <code>instance-attribute</code>","text":"<pre><code>summaries: dict[str, Any] | None\n</code></pre> <p>A map of property summaries, either a set of values, a range of values or a JSON Schema.</p>"},{"location":"api/stac/#rustac.Collection.title","title":"title  <code>instance-attribute</code>","text":"<pre><code>title: str | None\n</code></pre> <p>A short descriptive one-line title for the Collection.</p>"},{"location":"api/stac/#rustac.Collection.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[str]\n</code></pre> <p>Must be set to Collection to be a valid Collection.</p>"},{"location":"api/stac/#rustac.Item","title":"rustac.Item","text":"<p>               Bases: <code>TypedDict</code></p> <p>An Item is a GeoJSON Feature augmented with foreign members relevant to a STAC object.</p>"},{"location":"api/stac/#rustac.Item.assets","title":"assets  <code>instance-attribute</code>","text":"<pre><code>assets: Required[dict[str, Asset]]\n</code></pre> <p>Dictionary of asset objects that can be downloaded, each with a unique key.</p>"},{"location":"api/stac/#rustac.Item.bbox","title":"bbox  <code>instance-attribute</code>","text":"<pre><code>bbox: list[int | float] | None\n</code></pre> <p>REQUIRED if geometry is not null, prohibited if geometry is null.</p> <p>Bounding Box of the asset represented by this Item, formatted according to RFC 7946, section 5.</p>"},{"location":"api/stac/#rustac.Item.collection","title":"collection  <code>instance-attribute</code>","text":"<pre><code>collection: str | None\n</code></pre> <p>The id of the STAC Collection this Item references to.</p> <p>This field is required if a link with a collection relation type is present and is not allowed otherwise.</p>"},{"location":"api/stac/#rustac.Item.geometry","title":"geometry  <code>instance-attribute</code>","text":"<pre><code>geometry: dict[str, Any] | None\n</code></pre> <p>Defines the full footprint of the asset represented by this item, formatted according to RFC 7946, section 3.1 if a geometry is provided or section 3.2 if no geometry is provided.</p>"},{"location":"api/stac/#rustac.Item.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: Required[str]\n</code></pre> <p>Provider identifier. The ID should be unique within the Collection that contains the Item.</p>"},{"location":"api/stac/#rustac.Item.links","title":"links  <code>instance-attribute</code>","text":"<pre><code>links: Required[list[Link]]\n</code></pre> <p>List of link objects to resources and related URLs.</p> <p>See the best practices for details on when the use self links is strongly recommended.</p>"},{"location":"api/stac/#rustac.Item.properties","title":"properties  <code>instance-attribute</code>","text":"<pre><code>properties: Required[Properties]\n</code></pre> <p>A dictionary of additional metadata for the Item.</p>"},{"location":"api/stac/#rustac.Item.stac_extensions","title":"stac_extensions  <code>instance-attribute</code>","text":"<pre><code>stac_extensions: list[str] | None\n</code></pre> <p>A list of extensions the Item implements.</p>"},{"location":"api/stac/#rustac.Item.stac_version","title":"stac_version  <code>instance-attribute</code>","text":"<pre><code>stac_version: Required[str]\n</code></pre> <p>The STAC version the Item implements.</p>"},{"location":"api/stac/#rustac.Item.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: Required[str]\n</code></pre> <p>Type of the GeoJSON Object. MUST be set to Feature.</p>"},{"location":"api/stac/#rustac.ItemCollection","title":"rustac.ItemCollection","text":"<p>               Bases: <code>TypedDict</code></p> <p>A GeoJSON feature collection of STAC Items.</p>"},{"location":"api/stac/#rustac.ItemCollection.features","title":"features  <code>instance-attribute</code>","text":"<pre><code>features: list[Item]\n</code></pre> <p>STAC items.</p>"},{"location":"api/version/","title":"Version","text":""},{"location":"api/version/#rustac.sha","title":"rustac.sha","text":"<pre><code>sha() -&gt; str\n</code></pre> <p>Returns the SHA of the underlying rustac crate.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; rustac.sha()\n\"4d6a60a3df1386922285191aba95a76ec704a8b4\"\n</code></pre>"},{"location":"api/version/#rustac.version","title":"rustac.version","text":"<pre><code>version(\n    name: Literal[\"stac\"]\n    | Literal[\"stac-api\"]\n    | Literal[\"stac-duckdb\"]\n    | Literal[\"duckdb\"]\n    | None = None,\n) -&gt; str | None\n</code></pre> <p>Returns this package's version, or the version of a upstream.</p> <p>Parameters:</p> <ul> <li> <code>name</code>               (<code>Literal['stac'] | Literal['stac-api'] | Literal['stac-duckdb'] | Literal['duckdb'] | None</code>, default:                   <code>None</code> )           \u2013            <p>The name of the upstream version to return. Valid values are \"stac\", \"stac-api\", \"stac-duckdb\", or \"duckdb\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str | None</code>           \u2013            <p>The version, or None if the name is not recognized as an upstream.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; rustac.version()\n\"0.2.0\"\n&gt;&gt;&gt; rustac.version(\"duckdb\")\n\"1.0.0\"\n</code></pre>"},{"location":"api/walk/","title":"Walk","text":""},{"location":"api/walk/#rustac.walk","title":"rustac.walk","text":"<pre><code>walk(\n    container: dict[str, Any],\n) -&gt; AsyncIterator[\n    tuple[Catalog | Collection, list[Catalog | Collection], list[Item]]\n]\n</code></pre> <p>Recursively walks a STAC catalog or collection breadth-first.</p> <p>Parameters:</p> <ul> <li> <code>container</code>               (<code>dict[str, Any]</code>)           \u2013            <p>A STAC catalog or collection.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>AsyncIterator[tuple[Catalog | Collection, list[Catalog | Collection], list[Item]]]</code>           \u2013            <p>A three-tuple of the container, its children, and its items.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; async for container, children, items in rustac.walk(catalog):\n...     ...\n</code></pre>"},{"location":"api/write/","title":"Write","text":""},{"location":"api/write/#rustac.write","title":"rustac.write  <code>async</code>","text":"<pre><code>write(\n    href: str,\n    value: dict[str, Any] | Sequence[dict[str, Any]],\n    *,\n    format: str | None = None,\n    store: AnyObjectStore | None = None,\n) -&gt; dict[str, str] | None\n</code></pre> <p>Writes STAC to a href.</p> <p>Parameters:</p> <ul> <li> <code>href</code>               (<code>str</code>)           \u2013            <p>The href to write to</p> </li> <li> <code>value</code>               (<code>dict[str, Any] | Sequence[dict[str, Any]]</code>)           \u2013            <p>The value to write. This can be a STAC dictionary or a list of items.</p> </li> <li> <code>format</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The output format to write. If not provided, will be inferred from the href's extension.</p> </li> <li> <code>store</code>               (<code>AnyObjectStore | None</code>, default:                   <code>None</code> )           \u2013            <p>The object store to use for writing.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[str, str] | None</code>           \u2013            <p>The result of putting data into an object store, e.g. the e_tag and the version. None is returned if the file was written locally.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; with open(\"items.json\") as f:\n...     items = json.load(f)\n&gt;&gt;&gt; await rustac.write(\"items.parquet\", items)\n</code></pre>"},{"location":"api/store/","title":"ObjectStore","text":""},{"location":"api/store/#rustac.store.from_url","title":"rustac.store.from_url","text":"<pre><code>from_url(\n    url: str,\n    *,\n    config: S3Config | S3ConfigInput | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: S3CredentialProvider | None = None,\n    **kwargs: Unpack[S3ConfigInput],\n) -&gt; ObjectStore\n</code></pre><pre><code>from_url(\n    url: str,\n    *,\n    config: GCSConfig | GCSConfigInput | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: GCSCredentialProvider | None = None,\n    **kwargs: Unpack[GCSConfigInput],\n) -&gt; ObjectStore\n</code></pre><pre><code>from_url(\n    url: str,\n    *,\n    config: AzureConfig | AzureConfigInput | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: AzureCredentialProvider | None = None,\n    **kwargs: Unpack[AzureConfigInput],\n) -&gt; ObjectStore\n</code></pre><pre><code>from_url(\n    url: str,\n    *,\n    config: None = None,\n    client_options: None = None,\n    retry_config: None = None,\n    automatic_cleanup: bool = False,\n    mkdir: bool = False,\n) -&gt; ObjectStore\n</code></pre> <pre><code>from_url(\n    url: str,\n    *,\n    config: S3ConfigInput | GCSConfigInput | AzureConfigInput | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: Callable | None = None,\n    **kwargs: Any,\n) -&gt; ObjectStore\n</code></pre> <p>Easy construction of store by URL, identifying the relevant store.</p> <p>This will defer to a store-specific <code>from_url</code> constructor based on the provided <code>url</code>. E.g. passing <code>\"s3://bucket/path\"</code> will defer to <code>S3Store.from_url</code>.</p> <p>Supported formats:</p> <ul> <li><code>file:///path/to/my/file</code> -&gt; <code>LocalStore</code></li> <li><code>memory:///</code> -&gt; <code>MemoryStore</code></li> <li><code>s3://bucket/path</code> -&gt; <code>S3Store</code> (also supports <code>s3a</code>)</li> <li><code>gs://bucket/path</code> -&gt; <code>GCSStore</code></li> <li><code>az://account/container/path</code> -&gt; <code>AzureStore</code> (also   supports <code>adl</code>, <code>azure</code>, <code>abfs</code>, <code>abfss</code>)</li> <li><code>http://mydomain/path</code> -&gt; <code>HTTPStore</code></li> <li><code>https://mydomain/path</code> -&gt; <code>HTTPStore</code></li> </ul> <p>There are also special cases for AWS and Azure for <code>https://{host?}/path</code> paths:</p> <ul> <li><code>dfs.core.windows.net</code>, <code>blob.core.windows.net</code>, <code>dfs.fabric.microsoft.com</code>,   <code>blob.fabric.microsoft.com</code> -&gt; <code>AzureStore</code></li> <li><code>amazonaws.com</code> -&gt; <code>S3Store</code></li> <li><code>r2.cloudflarestorage.com</code> -&gt; <code>S3Store</code></li> </ul> <p>Note</p> <p>For best static typing, use the constructors on individual store classes directly.</p> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>well-known storage URL.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>S3ConfigInput | GCSConfigInput | AzureConfigInput | None</code>)           \u2013            <p>per-store Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>Callable | None</code>)           \u2013            <p>A callback to provide custom credentials to the underlying store classes.</p> </li> <li> <code>kwargs</code>               (<code>Any</code>)           \u2013            <p>per-store configuration passed down to store-specific builders.</p> </li> </ul>"},{"location":"api/store/#rustac.store.ObjectStore","title":"rustac.store.ObjectStore  <code>module-attribute</code>","text":"<pre><code>ObjectStore: TypeAlias = (\n    AzureStore | GCSStore | HTTPStore | S3Store | LocalStore | MemoryStore\n)\n</code></pre> <p>All supported ObjectStore implementations.</p>"},{"location":"api/store/aws/","title":"AWS S3","text":""},{"location":"api/store/aws/#rustac.store.S3Store","title":"rustac.store.S3Store","text":"<p>Interface to an Amazon S3 bucket.</p> <p>All constructors will check for environment variables. All environment variables starting with <code>AWS_</code> will be evaluated. Names must match keys from [<code>S3ConfigInput</code>][obstore.store.S3ConfigInput]. Only upper-case environment variables are accepted.</p> <p>Some examples of variables extracted from environment:</p> <ul> <li><code>AWS_ACCESS_KEY_ID</code> -&gt; access_key_id</li> <li><code>AWS_SECRET_ACCESS_KEY</code> -&gt; secret_access_key</li> <li><code>AWS_DEFAULT_REGION</code> -&gt; region</li> <li><code>AWS_ENDPOINT</code> -&gt; endpoint</li> <li><code>AWS_SESSION_TOKEN</code> -&gt; token</li> <li><code>AWS_CONTAINER_CREDENTIALS_RELATIVE_URI</code> -&gt; https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html</li> <li><code>AWS_REQUEST_PAYER</code> -&gt; set to \"true\" to permit requester-pays connections.</li> </ul> <p>Examples:</p> <p>Using requester-pays buckets:</p> <p>Pass <code>request_payer=True</code> as a keyword argument or have <code>AWS_REQUESTER_PAYS=True</code> set in the environment.</p> <p>Anonymous requests:</p> <p>Pass <code>skip_signature=True</code> as a keyword argument or have <code>AWS_SKIP_SIGNATURE=True</code> set in the environment.</p>"},{"location":"api/store/aws/#rustac.store.S3Store.client_options","title":"client_options  <code>property</code>","text":"<pre><code>client_options: ClientConfig | None\n</code></pre> <p>Get the store's client configuration.</p>"},{"location":"api/store/aws/#rustac.store.S3Store.config","title":"config  <code>property</code>","text":"<pre><code>config: S3Config\n</code></pre> <p>Get the underlying S3 config parameters.</p>"},{"location":"api/store/aws/#rustac.store.S3Store.prefix","title":"prefix  <code>property</code>","text":"<pre><code>prefix: str | None\n</code></pre> <p>Get the prefix applied to all operations in this store, if any.</p>"},{"location":"api/store/aws/#rustac.store.S3Store.retry_config","title":"retry_config  <code>property</code>","text":"<pre><code>retry_config: RetryConfig | None\n</code></pre> <p>Get the store's retry configuration.</p>"},{"location":"api/store/aws/#rustac.store.S3Store.__init__","title":"__init__","text":"<pre><code>__init__(\n    bucket: str | None = None,\n    *,\n    prefix: str | None = None,\n    config: S3Config | S3ConfigInput | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: S3CredentialProvider | None = None,\n    **kwargs: Unpack[S3ConfigInput],\n) -&gt; None\n</code></pre> <p>Create a new S3Store.</p> <p>Parameters:</p> <ul> <li> <code>bucket</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The AWS bucket to use.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | None</code>)           \u2013            <p>A prefix within the bucket to use for all operations.</p> </li> <li> <code>config</code>               (<code>S3Config | S3ConfigInput | None</code>)           \u2013            <p>AWS configuration. Values in this config will override values inferred from the environment. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>S3CredentialProvider | None</code>)           \u2013            <p>A callback to provide custom S3 credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[S3ConfigInput]</code>)           \u2013            <p>AWS configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>S3Store</p> </li> </ul>"},{"location":"api/store/aws/#rustac.store.S3Store.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    config: S3Config | S3ConfigInput | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: S3CredentialProvider | None = None,\n    **kwargs: Unpack[S3ConfigInput],\n) -&gt; S3Store\n</code></pre> <p>Parse available connection info from a well-known storage URL.</p> <p>The supported url schemes are:</p> <ul> <li><code>s3://&lt;bucket&gt;/&lt;path&gt;</code></li> <li><code>s3a://&lt;bucket&gt;/&lt;path&gt;</code></li> <li><code>https://s3.&lt;region&gt;.amazonaws.com/&lt;bucket&gt;</code></li> <li><code>https://&lt;bucket&gt;.s3.&lt;region&gt;.amazonaws.com</code></li> <li><code>https://ACCOUNT_ID.r2.cloudflarestorage.com/bucket</code></li> </ul> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>well-known storage URL.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>S3Config | S3ConfigInput | None</code>)           \u2013            <p>AWS Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>S3CredentialProvider | None</code>)           \u2013            <p>A callback to provide custom S3 credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[S3ConfigInput]</code>)           \u2013            <p>AWS configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>S3Store</code>           \u2013            <p>S3Store</p> </li> </ul>"},{"location":"api/store/aws/#rustac.store.S3Config","title":"rustac.store.S3Config","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration parameters returned from S3Store.config.</p> <p>Note that this is a strict subset of the keys allowed for input into the store, see [S3ConfigInput][obstore.store.S3ConfigInput].</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_access_key_id","title":"aws_access_key_id  <code>instance-attribute</code>","text":"<pre><code>aws_access_key_id: str\n</code></pre> <p>AWS Access Key</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_bucket","title":"aws_bucket  <code>instance-attribute</code>","text":"<pre><code>aws_bucket: str\n</code></pre> <p>Bucket name</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_checksum_algorithm","title":"aws_checksum_algorithm  <code>instance-attribute</code>","text":"<pre><code>aws_checksum_algorithm: str\n</code></pre> <p>Sets the checksum algorithm which has to be used for object integrity check during upload.</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_conditional_put","title":"aws_conditional_put  <code>instance-attribute</code>","text":"<pre><code>aws_conditional_put: str\n</code></pre> <p>See [<code>S3ConfigInput.aws_conditional_put</code>][obstore.store.S3ConfigInput.aws_conditional_put].</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_container_credentials_relative_uri","title":"aws_container_credentials_relative_uri  <code>instance-attribute</code>","text":"<pre><code>aws_container_credentials_relative_uri: str\n</code></pre> <p>See [<code>S3ConfigInput.aws_container_credentials_relative_uri</code>][obstore.store.S3ConfigInput.aws_container_credentials_relative_uri].</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_copy_if_not_exists","title":"aws_copy_if_not_exists  <code>instance-attribute</code>","text":"<pre><code>aws_copy_if_not_exists: str\n</code></pre> <p>See [<code>S3ConfigInput.aws_copy_if_not_exists</code>][obstore.store.S3ConfigInput.aws_copy_if_not_exists].</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_default_region","title":"aws_default_region  <code>instance-attribute</code>","text":"<pre><code>aws_default_region: str\n</code></pre> <p>Default region</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_disable_tagging","title":"aws_disable_tagging  <code>instance-attribute</code>","text":"<pre><code>aws_disable_tagging: bool\n</code></pre> <p>Disable tagging objects. This can be desirable if not supported by the backing store.</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_endpoint","title":"aws_endpoint  <code>instance-attribute</code>","text":"<pre><code>aws_endpoint: str\n</code></pre> <p>Sets custom endpoint for communicating with AWS S3.</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_imdsv1_fallback","title":"aws_imdsv1_fallback  <code>instance-attribute</code>","text":"<pre><code>aws_imdsv1_fallback: str\n</code></pre> <p>Fall back to ImdsV1</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_metadata_endpoint","title":"aws_metadata_endpoint  <code>instance-attribute</code>","text":"<pre><code>aws_metadata_endpoint: str\n</code></pre> <p>Set the instance metadata endpoint</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_region","title":"aws_region  <code>instance-attribute</code>","text":"<pre><code>aws_region: str\n</code></pre> <p>Region</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_request_payer","title":"aws_request_payer  <code>instance-attribute</code>","text":"<pre><code>aws_request_payer: bool\n</code></pre> <p>If <code>True</code>, enable operations on requester-pays buckets.</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_s3_express","title":"aws_s3_express  <code>instance-attribute</code>","text":"<pre><code>aws_s3_express: bool\n</code></pre> <p>Enable Support for S3 Express One Zone</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_secret_access_key","title":"aws_secret_access_key  <code>instance-attribute</code>","text":"<pre><code>aws_secret_access_key: str\n</code></pre> <p>Secret Access Key</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_server_side_encryption","title":"aws_server_side_encryption  <code>instance-attribute</code>","text":"<pre><code>aws_server_side_encryption: str\n</code></pre> <p>See [<code>S3ConfigInput.aws_server_side_encryption</code>][obstore.store.S3ConfigInput.aws_server_side_encryption].</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_session_token","title":"aws_session_token  <code>instance-attribute</code>","text":"<pre><code>aws_session_token: str\n</code></pre> <p>Token to use for requests (passed to underlying provider)</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_skip_signature","title":"aws_skip_signature  <code>instance-attribute</code>","text":"<pre><code>aws_skip_signature: bool\n</code></pre> <p>If <code>True</code>, S3Store will not fetch credentials and will not sign requests.</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_sse_bucket_key_enabled","title":"aws_sse_bucket_key_enabled  <code>instance-attribute</code>","text":"<pre><code>aws_sse_bucket_key_enabled: bool\n</code></pre> <p>If set to <code>True</code>, will use the bucket's default KMS key for server-side encryption. If set to <code>False</code>, will disable the use of the bucket's default KMS key for server-side encryption.</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_sse_customer_key_base64","title":"aws_sse_customer_key_base64  <code>instance-attribute</code>","text":"<pre><code>aws_sse_customer_key_base64: str\n</code></pre> <p>The base64 encoded, 256-bit customer encryption key to use for server-side encryption. If set, the server side encryption config value must be <code>\"sse-c\"</code>.</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_sse_kms_key_id","title":"aws_sse_kms_key_id  <code>instance-attribute</code>","text":"<pre><code>aws_sse_kms_key_id: str\n</code></pre> <p>The KMS key ID to use for server-side encryption.</p> <p>If set, the server side encryption config value must be <code>\"aws:kms\"</code> or <code>\"aws:kms:dsse\"</code>.</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_token","title":"aws_token  <code>instance-attribute</code>","text":"<pre><code>aws_token: str\n</code></pre> <p>Token to use for requests (passed to underlying provider)</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_unsigned_payload","title":"aws_unsigned_payload  <code>instance-attribute</code>","text":"<pre><code>aws_unsigned_payload: bool\n</code></pre> <p>Avoid computing payload checksum when calculating signature.</p>"},{"location":"api/store/aws/#rustac.store.S3Config.aws_virtual_hosted_style_request","title":"aws_virtual_hosted_style_request  <code>instance-attribute</code>","text":"<pre><code>aws_virtual_hosted_style_request: bool\n</code></pre> <p>If virtual hosted style request has to be used.</p>"},{"location":"api/store/aws/#rustac.store.S3Credential","title":"rustac.store.S3Credential","text":"<p>               Bases: <code>TypedDict</code></p> <p>An S3 credential.</p>"},{"location":"api/store/aws/#rustac.store.S3Credential.access_key_id","title":"access_key_id  <code>instance-attribute</code>","text":"<pre><code>access_key_id: str\n</code></pre> <p>AWS access key ID.</p>"},{"location":"api/store/aws/#rustac.store.S3Credential.expires_at","title":"expires_at  <code>instance-attribute</code>","text":"<pre><code>expires_at: datetime | None\n</code></pre> <p>Expiry datetime of credential. The datetime should have time zone set.</p> <p>If None, the credential will never expire.</p>"},{"location":"api/store/aws/#rustac.store.S3Credential.secret_access_key","title":"secret_access_key  <code>instance-attribute</code>","text":"<pre><code>secret_access_key: str\n</code></pre> <p>AWS secret access key</p>"},{"location":"api/store/aws/#rustac.store.S3Credential.token","title":"token  <code>instance-attribute</code>","text":"<pre><code>token: NotRequired[str | None]\n</code></pre> <p>AWS token.</p>"},{"location":"api/store/aws/#rustac.store.S3CredentialProvider","title":"rustac.store.S3CredentialProvider","text":"<p>               Bases: <code>Protocol</code></p> <p>A type hint for a synchronous or asynchronous callback to provide custom S3 credentials.</p> <p>This should be passed into the <code>credential_provider</code> parameter of <code>S3Store</code>.</p> <p>Examples:</p> <p>Return static credentials that don't expire: <pre><code>def get_credentials() -&gt; S3Credential:\n    return {\n        \"access_key_id\": \"...\",\n        \"secret_access_key\": \"...\",\n        \"token\": None,\n        \"expires_at\": None,\n    }\n</code></pre></p> <p>Return static credentials that are valid for 5 minutes: <pre><code>from datetime import datetime, timedelta, UTC\n\nasync def get_credentials() -&gt; S3Credential:\n    return {\n        \"access_key_id\": \"...\",\n        \"secret_access_key\": \"...\",\n        \"token\": None,\n        \"expires_at\": datetime.now(UTC) + timedelta(minutes=5),\n    }\n</code></pre></p> <p>A class-based credential provider with state:</p> <pre><code>from __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nimport boto3\nimport botocore.credentials\n\nif TYPE_CHECKING:\n    from obstore.store import S3Credential\n\n\nclass Boto3CredentialProvider:\n    credentials: botocore.credentials.Credentials\n\n    def __init__(self, session: boto3.session.Session) -&gt; None:\n        credentials = session.get_credentials()\n        if credentials is None:\n            raise ValueError(\"Received None from session.get_credentials\")\n\n        self.credentials = credentials\n\n    def __call__(self) -&gt; S3Credential:\n        frozen_credentials = self.credentials.get_frozen_credentials()\n        return {\n            \"access_key_id\": frozen_credentials.access_key,\n            \"secret_access_key\": frozen_credentials.secret_key,\n            \"token\": frozen_credentials.token,\n            \"expires_at\": None,\n        }\n</code></pre>"},{"location":"api/store/aws/#rustac.store.S3CredentialProvider.__call__","title":"__call__  <code>staticmethod</code>","text":"<pre><code>__call__() -&gt; S3Credential | Coroutine[Any, Any, S3Credential]\n</code></pre> <p>Return an <code>S3Credential</code>.</p>"},{"location":"api/store/azure/","title":"Microsoft Azure","text":""},{"location":"api/store/azure/#rustac.store.AzureStore","title":"rustac.store.AzureStore","text":"<p>Interface to a Microsoft Azure Blob Storage container.</p> <p>All constructors will check for environment variables. All environment variables starting with <code>AZURE_</code> will be evaluated. Names must match keys from <code>AzureConfig</code>. Only upper-case environment variables are accepted.</p> <p>Some examples of variables extracted from environment:</p> <ul> <li><code>AZURE_STORAGE_ACCOUNT_NAME</code>: storage account name</li> <li><code>AZURE_STORAGE_ACCOUNT_KEY</code>: storage account master key</li> <li><code>AZURE_STORAGE_ACCESS_KEY</code>: alias for <code>AZURE_STORAGE_ACCOUNT_KEY</code></li> <li><code>AZURE_STORAGE_CLIENT_ID</code> -&gt; client id for service principal authorization</li> <li><code>AZURE_STORAGE_CLIENT_SECRET</code> -&gt; client secret for service principal authorization</li> <li><code>AZURE_STORAGE_TENANT_ID</code> -&gt; tenant id used in oauth flows</li> </ul>"},{"location":"api/store/azure/#rustac.store.AzureStore.client_options","title":"client_options  <code>property</code>","text":"<pre><code>client_options: ClientConfig | None\n</code></pre> <p>Get the store's client configuration.</p>"},{"location":"api/store/azure/#rustac.store.AzureStore.config","title":"config  <code>property</code>","text":"<pre><code>config: AzureConfig\n</code></pre> <p>Get the underlying Azure config parameters.</p>"},{"location":"api/store/azure/#rustac.store.AzureStore.prefix","title":"prefix  <code>property</code>","text":"<pre><code>prefix: str | None\n</code></pre> <p>Get the prefix applied to all operations in this store, if any.</p>"},{"location":"api/store/azure/#rustac.store.AzureStore.retry_config","title":"retry_config  <code>property</code>","text":"<pre><code>retry_config: RetryConfig | None\n</code></pre> <p>Get the store's retry configuration.</p>"},{"location":"api/store/azure/#rustac.store.AzureStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    container: str | None = None,\n    *,\n    prefix: str | None = None,\n    config: AzureConfig | AzureConfigInput | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: AzureCredentialProvider | None = None,\n    **kwargs: Unpack[AzureConfigInput],\n) -&gt; None\n</code></pre> <p>Construct a new AzureStore.</p> <p>Parameters:</p> <ul> <li> <code>container</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>the name of the container.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | None</code>)           \u2013            <p>A prefix within the bucket to use for all operations.</p> </li> <li> <code>config</code>               (<code>AzureConfig | AzureConfigInput | None</code>)           \u2013            <p>Azure Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>AzureCredentialProvider | None</code>)           \u2013            <p>A callback to provide custom Azure credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[AzureConfigInput]</code>)           \u2013            <p>Azure configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>AzureStore</p> </li> </ul>"},{"location":"api/store/azure/#rustac.store.AzureStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    prefix: str | None = None,\n    config: AzureConfig | AzureConfigInput | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: AzureCredentialProvider | None = None,\n    **kwargs: Unpack[AzureConfigInput],\n) -&gt; AzureStore\n</code></pre> <p>Construct a new AzureStore with values populated from a well-known storage URL.</p> <p>The supported url schemes are:</p> <ul> <li><code>abfs[s]://&lt;container&gt;/&lt;path&gt;</code> (according to fsspec)</li> <li><code>abfs[s]://&lt;file_system&gt;@&lt;account_name&gt;.dfs.core.windows.net/&lt;path&gt;</code></li> <li><code>abfs[s]://&lt;file_system&gt;@&lt;account_name&gt;.dfs.fabric.microsoft.com/&lt;path&gt;</code></li> <li><code>az://&lt;container&gt;/&lt;path&gt;</code> (according to fsspec)</li> <li><code>adl://&lt;container&gt;/&lt;path&gt;</code> (according to fsspec)</li> <li><code>azure://&lt;container&gt;/&lt;path&gt;</code> (custom)</li> <li><code>https://&lt;account&gt;.dfs.core.windows.net</code></li> <li><code>https://&lt;account&gt;.blob.core.windows.net</code></li> <li><code>https://&lt;account&gt;.blob.core.windows.net/&lt;container&gt;</code></li> <li><code>https://&lt;account&gt;.dfs.fabric.microsoft.com</code></li> <li><code>https://&lt;account&gt;.dfs.fabric.microsoft.com/&lt;container&gt;</code></li> <li><code>https://&lt;account&gt;.blob.fabric.microsoft.com</code></li> <li><code>https://&lt;account&gt;.blob.fabric.microsoft.com/&lt;container&gt;</code></li> </ul> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>well-known storage URL.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | None</code>)           \u2013            <p>A prefix within the bucket to use for all operations.</p> </li> <li> <code>config</code>               (<code>AzureConfig | AzureConfigInput | None</code>)           \u2013            <p>Azure Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>AzureCredentialProvider | None</code>)           \u2013            <p>A callback to provide custom Azure credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[AzureConfigInput]</code>)           \u2013            <p>Azure configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>AzureStore</code>           \u2013            <p>AzureStore</p> </li> </ul>"},{"location":"api/store/azure/#rustac.store.AzureAccessKey","title":"rustac.store.AzureAccessKey","text":"<p>               Bases: <code>TypedDict</code></p> <p>A shared Azure Storage Account Key.</p> <p>https://learn.microsoft.com/en-us/rest/api/storageservices/authorize-with-shared-key</p>"},{"location":"api/store/azure/#rustac.store.AzureAccessKey.access_key","title":"access_key  <code>instance-attribute</code>","text":"<pre><code>access_key: str\n</code></pre> <p>Access key value.</p>"},{"location":"api/store/azure/#rustac.store.AzureAccessKey.expires_at","title":"expires_at  <code>instance-attribute</code>","text":"<pre><code>expires_at: datetime | None\n</code></pre> <p>Expiry datetime of credential. The datetime should have time zone set.</p> <p>If None, the credential will never expire.</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig","title":"rustac.store.AzureConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration parameters returned from AzureStore.config.</p> <p>Note that this is a strict subset of the keys allowed for input into the store, see [AzureConfigInput][obstore.store.AzureConfigInput].</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_container_name","title":"azure_container_name  <code>instance-attribute</code>","text":"<pre><code>azure_container_name: str\n</code></pre> <p>Container name</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_disable_tagging","title":"azure_disable_tagging  <code>instance-attribute</code>","text":"<pre><code>azure_disable_tagging: bool\n</code></pre> <p>Disables tagging objects</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_federated_token_file","title":"azure_federated_token_file  <code>instance-attribute</code>","text":"<pre><code>azure_federated_token_file: str\n</code></pre> <p>File containing token for Azure AD workload identity federation</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_msi_endpoint","title":"azure_msi_endpoint  <code>instance-attribute</code>","text":"<pre><code>azure_msi_endpoint: str\n</code></pre> <p>Endpoint to request a imds managed identity token</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_msi_resource_id","title":"azure_msi_resource_id  <code>instance-attribute</code>","text":"<pre><code>azure_msi_resource_id: str\n</code></pre> <p>Msi resource id for use with managed identity authentication</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_object_id","title":"azure_object_id  <code>instance-attribute</code>","text":"<pre><code>azure_object_id: str\n</code></pre> <p>Object id for use with managed identity authentication</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_skip_signature","title":"azure_skip_signature  <code>instance-attribute</code>","text":"<pre><code>azure_skip_signature: bool\n</code></pre> <p>Skip signing requests</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_storage_account_key","title":"azure_storage_account_key  <code>instance-attribute</code>","text":"<pre><code>azure_storage_account_key: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_storage_account_name","title":"azure_storage_account_name  <code>instance-attribute</code>","text":"<pre><code>azure_storage_account_name: str\n</code></pre> <p>The name of the azure storage account</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_storage_client_id","title":"azure_storage_client_id  <code>instance-attribute</code>","text":"<pre><code>azure_storage_client_id: str\n</code></pre> <p>Service principal client id for authorizing requests</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_storage_client_secret","title":"azure_storage_client_secret  <code>instance-attribute</code>","text":"<pre><code>azure_storage_client_secret: str\n</code></pre> <p>Service principal client secret for authorizing requests</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_storage_endpoint","title":"azure_storage_endpoint  <code>instance-attribute</code>","text":"<pre><code>azure_storage_endpoint: str\n</code></pre> <p>Override the endpoint used to communicate with blob storage</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_storage_sas_key","title":"azure_storage_sas_key  <code>instance-attribute</code>","text":"<pre><code>azure_storage_sas_key: str\n</code></pre> <p>Shared access signature.</p> <p>The signature is expected to be percent-encoded, <code>much</code>like they are provided in the azure storage explorer or azure portal.</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_storage_tenant_id","title":"azure_storage_tenant_id  <code>instance-attribute</code>","text":"<pre><code>azure_storage_tenant_id: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_storage_token","title":"azure_storage_token  <code>instance-attribute</code>","text":"<pre><code>azure_storage_token: str\n</code></pre> <p>Bearer token</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_storage_use_emulator","title":"azure_storage_use_emulator  <code>instance-attribute</code>","text":"<pre><code>azure_storage_use_emulator: bool\n</code></pre> <p>Use object store with azurite storage emulator</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_use_azure_cli","title":"azure_use_azure_cli  <code>instance-attribute</code>","text":"<pre><code>azure_use_azure_cli: bool\n</code></pre> <p>Use azure cli for acquiring access token</p>"},{"location":"api/store/azure/#rustac.store.AzureConfig.azure_use_fabric_endpoint","title":"azure_use_fabric_endpoint  <code>instance-attribute</code>","text":"<pre><code>azure_use_fabric_endpoint: bool\n</code></pre> <p>Use object store with url scheme account.dfs.fabric.microsoft.com</p>"},{"location":"api/store/azure/#rustac.store.AzureSASToken","title":"rustac.store.AzureSASToken","text":"<p>               Bases: <code>TypedDict</code></p> <p>A shared access signature.</p> <p>https://learn.microsoft.com/en-us/rest/api/storageservices/delegate-access-with-shared-access-signature</p>"},{"location":"api/store/azure/#rustac.store.AzureSASToken.expires_at","title":"expires_at  <code>instance-attribute</code>","text":"<pre><code>expires_at: datetime | None\n</code></pre> <p>Expiry datetime of credential. The datetime should have time zone set.</p> <p>If None, the credential will never expire.</p>"},{"location":"api/store/azure/#rustac.store.AzureSASToken.sas_token","title":"sas_token  <code>instance-attribute</code>","text":"<pre><code>sas_token: str | list[tuple[str, str]]\n</code></pre> <p>SAS token.</p>"},{"location":"api/store/azure/#rustac.store.AzureBearerToken","title":"rustac.store.AzureBearerToken","text":"<p>               Bases: <code>TypedDict</code></p> <p>An authorization token.</p> <p>https://learn.microsoft.com/en-us/rest/api/storageservices/authorize-with-azure-active-directory</p>"},{"location":"api/store/azure/#rustac.store.AzureBearerToken.expires_at","title":"expires_at  <code>instance-attribute</code>","text":"<pre><code>expires_at: datetime | None\n</code></pre> <p>Expiry datetime of credential. The datetime should have time zone set.</p> <p>If None, the credential will never expire.</p>"},{"location":"api/store/azure/#rustac.store.AzureBearerToken.token","title":"token  <code>instance-attribute</code>","text":"<pre><code>token: str\n</code></pre> <p>Bearer token.</p>"},{"location":"api/store/azure/#rustac.store.AzureCredential","title":"rustac.store.AzureCredential  <code>module-attribute</code>","text":"<pre><code>AzureCredential: TypeAlias = AzureAccessKey | AzureSASToken | AzureBearerToken\n</code></pre> <p>A type alias for supported azure credentials to be returned from <code>AzureCredentialProvider</code>.</p>"},{"location":"api/store/azure/#rustac.store.AzureCredentialProvider","title":"rustac.store.AzureCredentialProvider","text":"<p>               Bases: <code>Protocol</code></p> <p>A type hint for a synchronous or asynchronous callback to provide custom Azure credentials.</p> <p>This should be passed into the <code>credential_provider</code> parameter of <code>AzureStore</code>.</p>"},{"location":"api/store/azure/#rustac.store.AzureCredentialProvider.__call__","title":"__call__  <code>staticmethod</code>","text":"<pre><code>__call__() -&gt; AzureCredential | Coroutine[Any, Any, AzureCredential]\n</code></pre> <p>Return an <code>AzureCredential</code>.</p>"},{"location":"api/store/config/","title":"Configuration","text":""},{"location":"api/store/config/#rustac.store.ClientConfig","title":"rustac.store.ClientConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>HTTP client configuration.</p> <p>For timeout values (<code>connect_timeout</code>, <code>http2_keep_alive_timeout</code>, <code>pool_idle_timeout</code>, and <code>timeout</code>), values can either be Python <code>timedelta</code> objects, or they can be \"human-readable duration strings\".</p> <p>The human-readable duration string is a concatenation of time spans. Where each time span is an integer number and a suffix. Supported suffixes:</p> <ul> <li><code>nsec</code>, <code>ns</code> -- nanoseconds</li> <li><code>usec</code>, <code>us</code> -- microseconds</li> <li><code>msec</code>, <code>ms</code> -- milliseconds</li> <li><code>seconds</code>, <code>second</code>, <code>sec</code>, <code>s</code></li> <li><code>minutes</code>, <code>minute</code>, <code>min</code>, <code>m</code></li> <li><code>hours</code>, <code>hour</code>, <code>hr</code>, <code>h</code></li> <li><code>days</code>, <code>day</code>, <code>d</code></li> <li><code>weeks</code>, <code>week</code>, <code>w</code></li> <li><code>months</code>, <code>month</code>, <code>M</code> -- defined as 30.44 days</li> <li><code>years</code>, <code>year</code>, <code>y</code> -- defined as 365.25 days</li> </ul> <p>For example:</p> <ul> <li><code>\"2h 37min\"</code></li> <li><code>\"32ms\"</code></li> </ul>"},{"location":"api/store/config/#rustac.store.ClientConfig.allow_http","title":"allow_http  <code>instance-attribute</code>","text":"<pre><code>allow_http: bool\n</code></pre> <p>Allow non-TLS, i.e. non-HTTPS connections.</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.allow_invalid_certificates","title":"allow_invalid_certificates  <code>instance-attribute</code>","text":"<pre><code>allow_invalid_certificates: bool\n</code></pre> <p>Skip certificate validation on https connections.</p> <p>Warning</p> <p>You should think very carefully before using this method. If invalid certificates are trusted, any certificate for any site will be trusted for use. This includes expired certificates. This introduces significant vulnerabilities, and should only be used as a last resort or for testing</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.connect_timeout","title":"connect_timeout  <code>instance-attribute</code>","text":"<pre><code>connect_timeout: str | timedelta\n</code></pre> <p>Timeout for only the connect phase of a Client</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.default_content_type","title":"default_content_type  <code>instance-attribute</code>","text":"<pre><code>default_content_type: str\n</code></pre> <p>default <code>CONTENT_TYPE</code> for uploads</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.http1_only","title":"http1_only  <code>instance-attribute</code>","text":"<pre><code>http1_only: bool\n</code></pre> <p>Only use http1 connections.</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.http2_keep_alive_interval","title":"http2_keep_alive_interval  <code>instance-attribute</code>","text":"<pre><code>http2_keep_alive_interval: str\n</code></pre> <p>Interval for HTTP2 Ping frames should be sent to keep a connection alive.</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.http2_keep_alive_timeout","title":"http2_keep_alive_timeout  <code>instance-attribute</code>","text":"<pre><code>http2_keep_alive_timeout: str | timedelta\n</code></pre> <p>Timeout for receiving an acknowledgement of the keep-alive ping.</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.http2_keep_alive_while_idle","title":"http2_keep_alive_while_idle  <code>instance-attribute</code>","text":"<pre><code>http2_keep_alive_while_idle: str\n</code></pre> <p>Enable HTTP2 keep alive pings for idle connections</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.http2_only","title":"http2_only  <code>instance-attribute</code>","text":"<pre><code>http2_only: bool\n</code></pre> <p>Only use http2 connections</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.pool_idle_timeout","title":"pool_idle_timeout  <code>instance-attribute</code>","text":"<pre><code>pool_idle_timeout: str | timedelta\n</code></pre> <p>The pool max idle timeout.</p> <p>This is the length of time an idle connection will be kept alive.</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.pool_max_idle_per_host","title":"pool_max_idle_per_host  <code>instance-attribute</code>","text":"<pre><code>pool_max_idle_per_host: str\n</code></pre> <p>Maximum number of idle connections per host.</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.proxy_url","title":"proxy_url  <code>instance-attribute</code>","text":"<pre><code>proxy_url: str\n</code></pre> <p>HTTP proxy to use for requests.</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.timeout","title":"timeout  <code>instance-attribute</code>","text":"<pre><code>timeout: str | timedelta\n</code></pre> <p>Request timeout.</p> <p>The timeout is applied from when the request starts connecting until the response body has finished.</p>"},{"location":"api/store/config/#rustac.store.ClientConfig.user_agent","title":"user_agent  <code>instance-attribute</code>","text":"<pre><code>user_agent: str\n</code></pre> <p>User-Agent header to be used by this client.</p>"},{"location":"api/store/config/#rustac.store.BackoffConfig","title":"rustac.store.BackoffConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Exponential backoff with jitter.</p> <p>See https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/</p>"},{"location":"api/store/config/#rustac.store.BackoffConfig.base","title":"base  <code>instance-attribute</code>","text":"<pre><code>base: int | float\n</code></pre> <p>The base of the exponential to use.</p> <p>Defaults to <code>2</code>.</p>"},{"location":"api/store/config/#rustac.store.BackoffConfig.init_backoff","title":"init_backoff  <code>instance-attribute</code>","text":"<pre><code>init_backoff: timedelta\n</code></pre> <p>The initial backoff duration.</p> <p>Defaults to 100 milliseconds.</p>"},{"location":"api/store/config/#rustac.store.BackoffConfig.max_backoff","title":"max_backoff  <code>instance-attribute</code>","text":"<pre><code>max_backoff: timedelta\n</code></pre> <p>The maximum backoff duration.</p> <p>Defaults to 15 seconds.</p>"},{"location":"api/store/config/#rustac.store.RetryConfig","title":"rustac.store.RetryConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>The configuration for how to respond to request errors.</p> <p>The following categories of error will be retried:</p> <ul> <li>5xx server errors</li> <li>Connection errors</li> <li>Dropped connections</li> <li>Timeouts for safe / read-only requests</li> </ul> <p>Requests will be retried up to some limit, using exponential backoff with jitter. See <code>BackoffConfig</code> for more information</p>"},{"location":"api/store/config/#rustac.store.RetryConfig.backoff","title":"backoff  <code>instance-attribute</code>","text":"<pre><code>backoff: BackoffConfig\n</code></pre> <p>The backoff configuration.</p> <p>Defaults to the values listed above if not provided.</p>"},{"location":"api/store/config/#rustac.store.RetryConfig.max_retries","title":"max_retries  <code>instance-attribute</code>","text":"<pre><code>max_retries: int\n</code></pre> <p>The maximum number of times to retry a request</p> <p>Set to 0 to disable retries.</p> <p>Defaults to 10.</p>"},{"location":"api/store/config/#rustac.store.RetryConfig.retry_timeout","title":"retry_timeout  <code>instance-attribute</code>","text":"<pre><code>retry_timeout: timedelta\n</code></pre> <p>The maximum length of time from the initial request after which no further retries will be attempted</p> <p>This not only bounds the length of time before a server error will be surfaced to the application, but also bounds the length of time a request's credentials must remain valid.</p> <p>As requests are retried without renewing credentials or regenerating request payloads, this number should be kept below 5 minutes to avoid errors due to expired credentials and/or request payloads.</p> <p>Defaults to 3 minutes.</p>"},{"location":"api/store/gcs/","title":"Google Cloud Storage","text":""},{"location":"api/store/gcs/#rustac.store.GCSStore","title":"rustac.store.GCSStore","text":"<p>Interface to Google Cloud Storage.</p> <p>All constructors will check for environment variables. All environment variables starting with <code>GOOGLE_</code> will be evaluated. Names must match keys from <code>GCSConfig</code>. Only upper-case environment variables are accepted.</p> <p>Some examples of variables extracted from environment:</p> <ul> <li><code>GOOGLE_SERVICE_ACCOUNT</code>: location of service account file</li> <li><code>GOOGLE_SERVICE_ACCOUNT_PATH</code>: (alias) location of service account file</li> <li><code>SERVICE_ACCOUNT</code>: (alias) location of service account file</li> <li><code>GOOGLE_SERVICE_ACCOUNT_KEY</code>: JSON serialized service account key</li> <li><code>GOOGLE_BUCKET</code>: bucket name</li> <li><code>GOOGLE_BUCKET_NAME</code>: (alias) bucket name</li> </ul> <p>If no credentials are explicitly provided, they will be sourced from the environment as documented here.</p>"},{"location":"api/store/gcs/#rustac.store.GCSStore.client_options","title":"client_options  <code>property</code>","text":"<pre><code>client_options: ClientConfig | None\n</code></pre> <p>Get the store's client configuration.</p>"},{"location":"api/store/gcs/#rustac.store.GCSStore.config","title":"config  <code>property</code>","text":"<pre><code>config: GCSConfig\n</code></pre> <p>Get the underlying GCS config parameters.</p>"},{"location":"api/store/gcs/#rustac.store.GCSStore.prefix","title":"prefix  <code>property</code>","text":"<pre><code>prefix: str | None\n</code></pre> <p>Get the prefix applied to all operations in this store, if any.</p>"},{"location":"api/store/gcs/#rustac.store.GCSStore.retry_config","title":"retry_config  <code>property</code>","text":"<pre><code>retry_config: RetryConfig | None\n</code></pre> <p>Get the store's retry configuration.</p>"},{"location":"api/store/gcs/#rustac.store.GCSStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    bucket: str | None = None,\n    *,\n    prefix: str | None = None,\n    config: GCSConfig | GCSConfigInput | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: GCSCredentialProvider | None = None,\n    **kwargs: Unpack[GCSConfigInput],\n) -&gt; None\n</code></pre> <p>Construct a new GCSStore.</p> <p>Parameters:</p> <ul> <li> <code>bucket</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The GCS bucket to use.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | None</code>)           \u2013            <p>A prefix within the bucket to use for all operations.</p> </li> <li> <code>config</code>               (<code>GCSConfig | GCSConfigInput | None</code>)           \u2013            <p>GCS Configuration. Values in this config will override values inferred from the environment. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>GCSCredentialProvider | None</code>)           \u2013            <p>A callback to provide custom Google credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[GCSConfigInput]</code>)           \u2013            <p>GCS configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>GCSStore</p> </li> </ul>"},{"location":"api/store/gcs/#rustac.store.GCSStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    prefix: str | None = None,\n    config: GCSConfig | GCSConfigInput | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: GCSCredentialProvider | None = None,\n    **kwargs: Unpack[GCSConfigInput],\n) -&gt; GCSStore\n</code></pre> <p>Construct a new GCSStore with values populated from a well-known storage URL.</p> <p>The supported url schemes are:</p> <ul> <li><code>gs://&lt;bucket&gt;/&lt;path&gt;</code></li> </ul> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>well-known storage URL.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | None</code>)           \u2013            <p>A prefix within the bucket to use for all operations.</p> </li> <li> <code>config</code>               (<code>GCSConfig | GCSConfigInput | None</code>)           \u2013            <p>GCS Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>GCSCredentialProvider | None</code>)           \u2013            <p>A callback to provide custom Google credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[GCSConfigInput]</code>)           \u2013            <p>GCS configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GCSStore</code>           \u2013            <p>GCSStore</p> </li> </ul>"},{"location":"api/store/gcs/#rustac.store.GCSConfig","title":"rustac.store.GCSConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration parameters returned from GCSStore.config.</p> <p>Note that this is a strict subset of the keys allowed for input into the store, see [GCSConfigInput][obstore.store.GCSConfigInput].</p>"},{"location":"api/store/gcs/#rustac.store.GCSConfig.google_application_credentials","title":"google_application_credentials  <code>instance-attribute</code>","text":"<pre><code>google_application_credentials: str\n</code></pre> <p>Application credentials path.</p> <p>See https://cloud.google.com/docs/authentication/provide-credentials-adc.</p>"},{"location":"api/store/gcs/#rustac.store.GCSConfig.google_bucket","title":"google_bucket  <code>instance-attribute</code>","text":"<pre><code>google_bucket: str\n</code></pre> <p>Bucket name.</p>"},{"location":"api/store/gcs/#rustac.store.GCSConfig.google_service_account","title":"google_service_account  <code>instance-attribute</code>","text":"<pre><code>google_service_account: str\n</code></pre> <p>Path to the service account file.</p>"},{"location":"api/store/gcs/#rustac.store.GCSConfig.google_service_account_key","title":"google_service_account_key  <code>instance-attribute</code>","text":"<pre><code>google_service_account_key: str\n</code></pre> <p>The serialized service account key</p>"},{"location":"api/store/gcs/#rustac.store.GCSCredential","title":"rustac.store.GCSCredential","text":"<p>               Bases: <code>TypedDict</code></p> <p>A Google Cloud Storage Credential.</p>"},{"location":"api/store/gcs/#rustac.store.GCSCredential.expires_at","title":"expires_at  <code>instance-attribute</code>","text":"<pre><code>expires_at: datetime | None\n</code></pre> <p>Expiry datetime of credential. The datetime should have time zone set.</p> <p>If None, the credential will never expire.</p>"},{"location":"api/store/gcs/#rustac.store.GCSCredential.token","title":"token  <code>instance-attribute</code>","text":"<pre><code>token: str\n</code></pre> <p>An HTTP bearer token.</p>"},{"location":"api/store/gcs/#rustac.store.GCSCredentialProvider","title":"rustac.store.GCSCredentialProvider","text":"<p>               Bases: <code>Protocol</code></p> <p>A type hint for a synchronous or asynchronous callback to provide custom Google Cloud Storage credentials.</p> <p>This should be passed into the <code>credential_provider</code> parameter of <code>GCSStore</code>.</p>"},{"location":"api/store/gcs/#rustac.store.GCSCredentialProvider.__call__","title":"__call__  <code>staticmethod</code>","text":"<pre><code>__call__() -&gt; GCSCredential | Coroutine[Any, Any, GCSCredential]\n</code></pre> <p>Return a <code>GCSCredential</code>.</p>"},{"location":"api/store/http/","title":"HTTP","text":""},{"location":"api/store/http/#rustac.store.HTTPStore","title":"rustac.store.HTTPStore","text":"<p>Configure a connection to a generic HTTP server.</p> <p>Example</p> <p>Accessing the number of stars for a repo:</p> <pre><code>import json\n\nimport obstore as obs\nfrom obstore.store import HTTPStore\n\nstore = HTTPStore.from_url(\"https://api.github.com\")\nresp = obs.get(store, \"repos/developmentseed/obstore\")\ndata = json.loads(resp.bytes())\nprint(data[\"stargazers_count\"])\n</code></pre>"},{"location":"api/store/http/#rustac.store.HTTPStore.client_options","title":"client_options  <code>property</code>","text":"<pre><code>client_options: ClientConfig | None\n</code></pre> <p>Get the store's client configuration.</p>"},{"location":"api/store/http/#rustac.store.HTTPStore.retry_config","title":"retry_config  <code>property</code>","text":"<pre><code>retry_config: RetryConfig | None\n</code></pre> <p>Get the store's retry configuration.</p>"},{"location":"api/store/http/#rustac.store.HTTPStore.url","title":"url  <code>property</code>","text":"<pre><code>url: str\n</code></pre> <p>Get the base url of this store.</p>"},{"location":"api/store/http/#rustac.store.HTTPStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    url: str,\n    *,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n) -&gt; None\n</code></pre> <p>Construct a new HTTPStore from a URL.</p> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>The base URL to use for the store.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>HTTPStore</p> </li> </ul>"},{"location":"api/store/http/#rustac.store.HTTPStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n) -&gt; HTTPStore\n</code></pre> <p>Construct a new HTTPStore from a URL.</p> <p>This is an alias of <code>HTTPStore.__init__</code>.</p>"},{"location":"api/store/local/","title":"Local","text":""},{"location":"api/store/local/#rustac.store.LocalStore","title":"rustac.store.LocalStore","text":"<p>An ObjectStore interface to local filesystem storage.</p> <p>Can optionally be created with a directory prefix.</p> <pre><code>from pathlib import Path\n\nstore = LocalStore()\nstore = LocalStore(prefix=\"/path/to/directory\")\nstore = LocalStore(prefix=Path(\".\"))\n</code></pre>"},{"location":"api/store/local/#rustac.store.LocalStore.prefix","title":"prefix  <code>property</code>","text":"<pre><code>prefix: Path | None\n</code></pre> <p>Get the prefix applied to all operations in this store, if any.</p>"},{"location":"api/store/local/#rustac.store.LocalStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    prefix: str | Path | None = None,\n    *,\n    automatic_cleanup: bool = False,\n    mkdir: bool = False,\n) -&gt; None\n</code></pre> <p>Create a new LocalStore.</p> <p>Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | Path | None</code>, default:                   <code>None</code> )           \u2013            <p>Use the specified prefix applied to all paths. Defaults to <code>None</code>.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>automatic_cleanup</code>               (<code>bool</code>)           \u2013            <p>if <code>True</code>, enables automatic cleanup of empty directories when deleting files. Defaults to False.</p> </li> <li> <code>mkdir</code>               (<code>bool</code>)           \u2013            <p>if <code>True</code> and <code>prefix</code> is not <code>None</code>, the directory at <code>prefix</code> will attempt to be created. Note that this root directory will not be cleaned up, even if <code>automatic_cleanup</code> is <code>True</code>.</p> </li> </ul>"},{"location":"api/store/local/#rustac.store.LocalStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str, *, automatic_cleanup: bool = False, mkdir: bool = False\n) -&gt; LocalStore\n</code></pre> <p>Construct a new LocalStore from a <code>file://</code> URL.</p> <p>Examples:</p> <p>Construct a new store pointing to the root of your filesystem: <pre><code>url = \"file:///\"\nstore = LocalStore.from_url(url)\n</code></pre></p> <p>Construct a new store with a directory prefix: <pre><code>url = \"file:///Users/kyle/\"\nstore = LocalStore.from_url(url)\n</code></pre></p>"},{"location":"api/store/memory/","title":"Memory","text":""},{"location":"api/store/memory/#rustac.store.MemoryStore","title":"rustac.store.MemoryStore","text":"<p>A fully in-memory implementation of ObjectStore.</p> <p>Create a new in-memory store: <pre><code>store = MemoryStore()\n</code></pre></p>"},{"location":"notebooks/","title":"Notebooks","text":"<p>Examples of using rustac in Jupyter notebooks.</p>"},{"location":"notebooks/its-live/","title":"ITS_LIVE case study","text":"In\u00a0[2]: Copied! <pre>from pathlib import Path\nfrom obstore.store import S3Store\n\ndestination = Path(\"../../data/its-live\")\nsource_store = S3Store(\n    bucket=\"its-live-data\", prefix=\"test-space/stac_catalogs/landsatOLI/v02\"\n)\n</pre> from pathlib import Path from obstore.store import S3Store  destination = Path(\"../../data/its-live\") source_store = S3Store(     bucket=\"its-live-data\", prefix=\"test-space/stac_catalogs/landsatOLI/v02\" ) <p>Let's list all of the ndjson files.</p> In\u00a0[3]: Copied! <pre>import humanize\n\npaths = []\nsizes = []\nfor list_stream in source_store.list():\n    for object_meta in list_stream:\n        paths.append(object_meta[\"path\"])\n        sizes.append(object_meta[\"size\"])\n\nprint(\n    f\"Found {len(paths)} paths with sizes ranging from {humanize.naturalsize(min(sizes))} to {humanize.naturalsize(max(sizes))}\"\n)\nprint(f\"Total size of the files is {humanize.naturalsize(sum(sizes))}\")\n</pre> import humanize  paths = [] sizes = [] for list_stream in source_store.list():     for object_meta in list_stream:         paths.append(object_meta[\"path\"])         sizes.append(object_meta[\"size\"])  print(     f\"Found {len(paths)} paths with sizes ranging from {humanize.naturalsize(min(sizes))} to {humanize.naturalsize(max(sizes))}\" ) print(f\"Total size of the files is {humanize.naturalsize(sum(sizes))}\") <pre>Found 5134 paths with sizes ranging from 2.9 kB to 233.0 MB\nTotal size of the files is 28.7 GB\n</pre> <p>That's a lot of data! We'd like to make one or more STAC Collections from it, but we don't really want to store that much ndjson locally. stac-geoparquet is much more compact (especially when compressed) so let's copy-and-convert.</p> <p>This will take a while, on the order of an hour or two. An implementation using in-region resources would be faster.</p> <p>Backfilling errors</p> <p>         The block includes a check for already-existing files, so you can run it multiple times to pick up any files that errored.     </p> In\u00a0[\u00a0]: Copied! <pre>from asyncio import TaskGroup, Semaphore\nimport tqdm\nimport rustac\n\n# Limit the number of files we hold in memory at a time\nsemaphore = Semaphore(10)\n# Store the ones that error, it's the internet after all, things will error\nmissed_paths = []\n\n\nasync def copy_and_convert(\n    source_path: str, source_store, destination_path: Path, progress_bar: tqdm.tqdm\n) -&gt; None:\n    async with semaphore:\n        try:\n            value = await rustac.read(source_path, store=source_store)\n        except Exception:\n            missed_paths.append(path)\n            progress_bar.update()\n            return\n\n        # ndjson with only one item are read as an item, not a item collection\n        if value[\"type\"] == \"Feature\":\n            await rustac.write(str(destination_path), [value])\n        else:\n            assert value[\"type\"] == \"FeatureCollection\"\n            await rustac.write(str(destination_path), value)\n\n        progress_bar.update()\n\n\nprogress_bar = tqdm.tqdm(total=len(paths), miniters=1)\nasync with TaskGroup() as task_group:\n    for path in paths:\n        destination_path = Path(destination / path).with_suffix(\".parquet\")\n        if destination_path.exists():\n            progress_bar.update()\n        else:\n            task_group.create_task(\n                copy_and_convert(path, source_store, destination_path, progress_bar)\n            )\n</pre> from asyncio import TaskGroup, Semaphore import tqdm import rustac  # Limit the number of files we hold in memory at a time semaphore = Semaphore(10) # Store the ones that error, it's the internet after all, things will error missed_paths = []   async def copy_and_convert(     source_path: str, source_store, destination_path: Path, progress_bar: tqdm.tqdm ) -&gt; None:     async with semaphore:         try:             value = await rustac.read(source_path, store=source_store)         except Exception:             missed_paths.append(path)             progress_bar.update()             return          # ndjson with only one item are read as an item, not a item collection         if value[\"type\"] == \"Feature\":             await rustac.write(str(destination_path), [value])         else:             assert value[\"type\"] == \"FeatureCollection\"             await rustac.write(str(destination_path), value)          progress_bar.update()   progress_bar = tqdm.tqdm(total=len(paths), miniters=1) async with TaskGroup() as task_group:     for path in paths:         destination_path = Path(destination / path).with_suffix(\".parquet\")         if destination_path.exists():             progress_bar.update()         else:             task_group.create_task(                 copy_and_convert(path, source_store, destination_path, progress_bar)             ) <p>Alright! Let's see what we got.</p> In\u00a0[6]: Copied! <pre>import os.path\n\nprint(f\"{len(missed_paths)} files errored\")\n\ncount = 0\nsize = 0\nfor path in destination.glob(\"**/*.parquet\"):\n    count += 1\n    size += os.path.getsize(path)\n\nprint(f\"The {count} stac-geoparquet files are {humanize.naturalsize(size)}\")\nprint(f\"That's {100 * size / sum(sizes):.2f}% of the original size\")\n</pre> import os.path  print(f\"{len(missed_paths)} files errored\")  count = 0 size = 0 for path in destination.glob(\"**/*.parquet\"):     count += 1     size += os.path.getsize(path)  print(f\"The {count} stac-geoparquet files are {humanize.naturalsize(size)}\") print(f\"That's {100 * size / sum(sizes):.2f}% of the original size\") <pre>0 files errored\nThe 5134 stac-geoparquet files are 3.6 GB\nThat's 12.53% of the original size\n</pre> <p>Very cool. We can use DuckDB to search into the files.</p> In\u00a0[7]: Copied! <pre>import duckdb\n\nduckdb.sql(f\"select count(*) from read_parquet('{destination}/**/*.parquet')\")\n</pre> import duckdb  duckdb.sql(f\"select count(*) from read_parquet('{destination}/**/*.parquet')\") Out[7]: <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 count_star() \u2502\n\u2502    int64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      9907260 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518</pre> <p>DuckDB recommends that each partition contains 100 MB of data, but some of our files are much smaller. Let's re-partition our data by year to get larger partitions.</p> In\u00a0[22]: Copied! <pre>partitioned_destination = \"../../data/its-live-partitioned\"\n# We limit the number of open files to not hose our processor, it defaults to 100\nduckdb.sql(\"set partitioned_write_max_open_files = 4;\")\nduckdb.sql(\n    f\"copy (select *, year(datetime) as year from read_parquet('{destination}/**/*.parquet', union_by_name=true)) to '{partitioned_destination}' (format parquet, partition_by (year), overwrite_or_ignore)\"\n)\n</pre> partitioned_destination = \"../../data/its-live-partitioned\" # We limit the number of open files to not hose our processor, it defaults to 100 duckdb.sql(\"set partitioned_write_max_open_files = 4;\") duckdb.sql(     f\"copy (select *, year(datetime) as year from read_parquet('{destination}/**/*.parquet', union_by_name=true)) to '{partitioned_destination}' (format parquet, partition_by (year), overwrite_or_ignore)\" ) <p>We can now query by year effectively.</p> In\u00a0[24]: Copied! <pre>duckdb.sql(\n    f\"select count(*) from read_parquet('{partitioned_destination}/**/*.parquet') where year = 2024\"\n)\n</pre> duckdb.sql(     f\"select count(*) from read_parquet('{partitioned_destination}/**/*.parquet') where year = 2024\" ) Out[24]: <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 count_star() \u2502\n\u2502    int64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      1278258 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518</pre> In\u00a0[19]: Copied! <pre>duckdb.sql(\n    f\"select column_name from (describe select * from read_parquet('{partitioned_destination}/**/*.parquet'))\"\n)\n</pre> duckdb.sql(     f\"select column_name from (describe select * from read_parquet('{partitioned_destination}/**/*.parquet'))\" ) Out[19]: <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     column_name      \u2502\n\u2502       varchar        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 type                 \u2502\n\u2502 stac_version         \u2502\n\u2502 stac_extensions      \u2502\n\u2502 id                   \u2502\n\u2502 version              \u2502\n\u2502 proj:code            \u2502\n\u2502 links                \u2502\n\u2502 assets               \u2502\n\u2502 collection           \u2502\n\u2502 datetime             \u2502\n\u2502    \u00b7                 \u2502\n\u2502    \u00b7                 \u2502\n\u2502    \u00b7                 \u2502\n\u2502 platform             \u2502\n\u2502 scene_1_id           \u2502\n\u2502 scene_2_id           \u2502\n\u2502 scene_1_path_row     \u2502\n\u2502 scene_2_path_row     \u2502\n\u2502 sat:orbit_state      \u2502\n\u2502 percent_valid_pixels \u2502\n\u2502 bbox                 \u2502\n\u2502 geometry             \u2502\n\u2502 year                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  27 rows (20 shown)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518</pre> <p>Each partition's files is still stac-geoparquet, so we can read them back in if we want. Most of them are pretty big, so we intentionally pick a smaller one for this example.</p> In\u00a0[10]: Copied! <pre>item_collection = await rustac.read(\n    str(Path(partitioned_destination) / \"year=1982\" / \"data_0.parquet\")\n)\nprint(len(item_collection[\"features\"]))\n</pre> item_collection = await rustac.read(     str(Path(partitioned_destination) / \"year=1982\" / \"data_0.parquet\") ) print(len(item_collection[\"features\"])) <pre>23\n</pre> In\u00a0[15]: Copied! <pre>import cql2\n\nhref = str(Path(partitioned_destination) / \"**\" / \"*.parquet\")\ncql2_json = cql2.parse_text(\"percent_valid_pixels=100\").to_json()\nitems = await rustac.search(href, filter=cql2_json)\nprint(len(items))\n</pre> import cql2  href = str(Path(partitioned_destination) / \"**\" / \"*.parquet\") cql2_json = cql2.parse_text(\"percent_valid_pixels=100\").to_json() items = await rustac.search(href, filter=cql2_json) print(len(items)) <pre>39696\n</pre> <p>If we know we're going to go to a geopandas <code>GeoDataFrame</code>, we can search directly to an arrow table to make things a bit more efficient. To do so, we'll need to use rustac's <code>DuckdbClient</code>.</p> In\u00a0[18]: Copied! <pre>from rustac import DuckdbClient\nfrom geopandas import GeoDataFrame\n\nclient = DuckdbClient()\ntable = client.search_to_arrow(href, filter=cql2_json)\ndata_frame = GeoDataFrame.from_arrow(table)\ndata_frame.plot()\n</pre> from rustac import DuckdbClient from geopandas import GeoDataFrame  client = DuckdbClient() table = client.search_to_arrow(href, filter=cql2_json) data_frame = GeoDataFrame.from_arrow(table) data_frame.plot() Out[18]: <pre>&lt;Axes: &gt;</pre>"},{"location":"notebooks/its-live/#its_live-case-study","title":"ITS_LIVE case study\u00b6","text":"<p>An example of using rustac with ITS_LIVE STAC data. We'll start just by looking at the Landsat ndjson.</p> <p>AWS credentials</p> <p>         You'll want to make sure you're running this notebook with your AWS credentials configured in your environment, and set your default region to us-west-2.     </p>"},{"location":"notebooks/its-live/#searching","title":"Searching\u00b6","text":"<p>One of rustac's features is the ability to use STAC API search against stac-geoparquet files, no server required. We can use a cql2 filter to query by attributes.</p>"},{"location":"notebooks/read/","title":"Reading and plotting","text":"In\u00a0[4]: Copied! <pre>import rustac\n\nitems = await rustac.read(\n    \"https://github.com/stac-utils/rustac-py/raw/refs/heads/main/data/100-sentinel-2-items.parquet\"\n)\nlen(items[\"features\"])\n</pre> import rustac  items = await rustac.read(     \"https://github.com/stac-utils/rustac-py/raw/refs/heads/main/data/100-sentinel-2-items.parquet\" ) len(items[\"features\"]) Out[4]: <pre>100</pre> <p>Let's take a look at some of the attributes of our STAC items.</p> In\u00a0[5]: Copied! <pre>import pandas\nfrom geopandas import GeoDataFrame\n\ndata_frame = GeoDataFrame.from_features(items)\ndata_frame[\"datetime\"] = pandas.to_datetime(data_frame[\"datetime\"])\ndata_frame[[\"geometry\", \"datetime\", \"s2:snow_ice_percentage\"]]\n</pre> import pandas from geopandas import GeoDataFrame  data_frame = GeoDataFrame.from_features(items) data_frame[\"datetime\"] = pandas.to_datetime(data_frame[\"datetime\"]) data_frame[[\"geometry\", \"datetime\", \"s2:snow_ice_percentage\"]] Out[5]: geometry datetime s2:snow_ice_percentage 0 POLYGON ((-105.36543 39.65938, -105.34153 39.7... 2024-12-03 17:46:29.024000+00:00 3.488287 1 POLYGON ((-106.18317 40.64479, -104.88456 40.6... 2024-12-01 17:57:21.024000+00:00 47.351283 2 POLYGON ((-105.35345 39.65943, -105.33389 39.7... 2024-11-28 17:47:01.025000+00:00 56.806326 3 POLYGON ((-106.18317 40.64479, -104.88456 40.6... 2024-11-26 17:56:09.024000+00:00 0.588352 4 POLYGON ((-105.37083 39.65936, -105.34293 39.7... 2024-11-23 17:45:59.024000+00:00 0.048005 ... ... ... ... 95 POLYGON ((-106.18317 40.64479, -104.88456 40.6... 2024-04-05 17:49:01.024000+00:00 48.347121 96 POLYGON ((-105.35378 39.65943, -105.34822 39.6... 2024-04-02 17:39:01.024000+00:00 4.604056 97 POLYGON ((-106.18317 40.64479, -104.88456 40.6... 2024-03-31 17:49:09.024000+00:00 23.157783 98 POLYGON ((-105.36759 39.65937, -105.33057 39.7... 2024-03-28 17:38:59.024000+00:00 3.135089 99 POLYGON ((-106.18317 40.64479, -104.88456 40.6... 2024-03-26 17:49:51.024000+00:00 32.571989 <p>100 rows \u00d7 3 columns</p> <p>How does the snow and ice percentage vary over the year?</p> In\u00a0[3]: Copied! <pre>from matplotlib.dates import DateFormatter\n\naxis = data_frame.plot(x=\"datetime\", y=\"s2:snow_ice_percentage\", kind=\"scatter\")\naxis.xaxis.set_major_formatter(DateFormatter(\"%b\"))\n</pre> from matplotlib.dates import DateFormatter  axis = data_frame.plot(x=\"datetime\", y=\"s2:snow_ice_percentage\", kind=\"scatter\") axis.xaxis.set_major_formatter(DateFormatter(\"%b\"))"},{"location":"notebooks/read/#reading-and-plotting","title":"Reading and plotting\u00b6","text":"<p>Read with our top-level <code>async</code> function.</p>"},{"location":"notebooks/search/","title":"Searching","text":"In\u00a0[4]: Copied! <pre>import contextily\nimport pandas\nimport rustac\nfrom geopandas import GeoDataFrame\n\nitems = await rustac.search(\n    \"https://stac.eoapi.dev\", collections=\"MAXAR_Marshall_Fire_21_Update\"\n)\ndata_frame = GeoDataFrame.from_features(items)\ndata_frame[\"datetime\"] = pandas.to_datetime(data_frame[\"datetime\"])\naxis = data_frame.set_crs(epsg=4326).to_crs(epsg=3857).plot(alpha=0.5, edgecolor=\"k\")\ncontextily.add_basemap(axis, source=contextily.providers.CartoDB.Positron)\naxis.set_axis_off()\n</pre> import contextily import pandas import rustac from geopandas import GeoDataFrame  items = await rustac.search(     \"https://stac.eoapi.dev\", collections=\"MAXAR_Marshall_Fire_21_Update\" ) data_frame = GeoDataFrame.from_features(items) data_frame[\"datetime\"] = pandas.to_datetime(data_frame[\"datetime\"]) axis = data_frame.set_crs(epsg=4326).to_crs(epsg=3857).plot(alpha=0.5, edgecolor=\"k\") contextily.add_basemap(axis, source=contextily.providers.CartoDB.Positron) axis.set_axis_off() <p>Search stac-geoparquet with DuckDB, no servers required!</p> In\u00a0[5]: Copied! <pre>items = await rustac.search(\n    \"../../data/100-sentinel-2-items.parquet\",\n    datetime=\"2024-12-01T00:00:00Z/..\",\n)\ndata_frame = GeoDataFrame.from_features(items)\ndata_frame[\"datetime\"] = pandas.to_datetime(data_frame[\"datetime\"])\ndata_frame[[\"datetime\", \"geometry\"]]\n</pre> items = await rustac.search(     \"../../data/100-sentinel-2-items.parquet\",     datetime=\"2024-12-01T00:00:00Z/..\", ) data_frame = GeoDataFrame.from_features(items) data_frame[\"datetime\"] = pandas.to_datetime(data_frame[\"datetime\"]) data_frame[[\"datetime\", \"geometry\"]] Out[5]: datetime geometry 0 2024-12-03 17:46:29.024000+00:00 POLYGON ((-105.36543 39.65938, -105.34153 39.7... 1 2024-12-01 17:57:21.024000+00:00 POLYGON ((-106.18317 40.64479, -104.88456 40.6... <p>If you know you're going to a <code>geopandas.GeoDataFrame</code>(or something else that speaks arrow), you can use the <code>arrow</code> optional dependency for rustac (<code>pip install 'rustac[arrow]'</code>) and search directly to arrow, which can be more efficient than going through JSON dictionaries.</p> In\u00a0[6]: Copied! <pre>from rustac import DuckdbClient\n\nclient = DuckdbClient()\ntable = client.search_to_arrow(\n    \"../../data/100-sentinel-2-items.parquet\",\n    datetime=\"2024-12-01T00:00:00Z/..\",\n)\ndata_frame = GeoDataFrame.from_arrow(table)\ndata_frame[[\"datetime\", \"geometry\"]]\n</pre> from rustac import DuckdbClient  client = DuckdbClient() table = client.search_to_arrow(     \"../../data/100-sentinel-2-items.parquet\",     datetime=\"2024-12-01T00:00:00Z/..\", ) data_frame = GeoDataFrame.from_arrow(table) data_frame[[\"datetime\", \"geometry\"]] Out[6]: datetime geometry 0 2024-12-03 10:46:29.024000-07:00 POLYGON ((-105.36543 39.65938, -105.34153 39.7... 1 2024-12-01 10:57:21.024000-07:00 POLYGON ((-106.18317 40.64479, -104.88456 40.6..."},{"location":"notebooks/search/#searching","title":"Searching\u00b6","text":"<p>Search a STAC API with <code>rustac.search</code>.</p>"},{"location":"notebooks/stac-geoparquet/","title":"stac-geoparquet","text":"In\u00a0[68]: Copied! <pre>from typing import Any\nimport os\nimport datetime\nimport humanize\nimport rustac\n\n\ndef create_item(\n    id: str, dt: datetime.datetime, extra_properties: dict[str, Any] | None = None\n) -&gt; dict[str, Any]:\n    properties = {\n        \"datetime\": dt.isoformat(),\n    }\n    if extra_properties:\n        properties.update(extra_properties)\n    return {\n        \"type\": \"Feature\",\n        \"stac_version\": \"1.1.0\",\n        \"id\": id,\n        \"geometry\": {\"type\": \"Point\", \"coordinates\": [-105.1019, 40.1672]},\n        \"bbox\": [-105.1019, 40.1672, -105.1019, 40.1672],\n        \"properties\": properties,\n        # Assets can't be empty at the moment: https://github.com/stac-utils/rustac/issues/766\n        \"assets\": {\n            \"data\": {\n                \"href\": \"https://storage.googleapis.com/open-cogs/stac-examples/20201211_223832_CS2.jpg\"\n            }\n        },\n        \"links\": [],\n    }\n\n\nitems = [\n    create_item(\n        f\"item-{i}\",\n        datetime.datetime(2024, 1, 1, tzinfo=datetime.timezone.utc)\n        + datetime.timedelta(hours=i),\n    )\n    for i in range(10000)\n]\nawait rustac.write(\"items.parquet\", items)\nprint(humanize.naturalsize(os.path.getsize(\"items.parquet\")))\n</pre> from typing import Any import os import datetime import humanize import rustac   def create_item(     id: str, dt: datetime.datetime, extra_properties: dict[str, Any] | None = None ) -&gt; dict[str, Any]:     properties = {         \"datetime\": dt.isoformat(),     }     if extra_properties:         properties.update(extra_properties)     return {         \"type\": \"Feature\",         \"stac_version\": \"1.1.0\",         \"id\": id,         \"geometry\": {\"type\": \"Point\", \"coordinates\": [-105.1019, 40.1672]},         \"bbox\": [-105.1019, 40.1672, -105.1019, 40.1672],         \"properties\": properties,         # Assets can't be empty at the moment: https://github.com/stac-utils/rustac/issues/766         \"assets\": {             \"data\": {                 \"href\": \"https://storage.googleapis.com/open-cogs/stac-examples/20201211_223832_CS2.jpg\"             }         },         \"links\": [],     }   items = [     create_item(         f\"item-{i}\",         datetime.datetime(2024, 1, 1, tzinfo=datetime.timezone.utc)         + datetime.timedelta(hours=i),     )     for i in range(10000) ] await rustac.write(\"items.parquet\", items) print(humanize.naturalsize(os.path.getsize(\"items.parquet\"))) <pre>150.2 kB\n</pre> <p>Reading is just as simple.</p> In\u00a0[69]: Copied! <pre>import json\n\nitem_collection = await rustac.read(\"items.parquet\")\nprint(json.dumps(item_collection[\"features\"][0], indent=2))\n</pre> import json  item_collection = await rustac.read(\"items.parquet\") print(json.dumps(item_collection[\"features\"][0], indent=2)) <pre>{\n  \"type\": \"Feature\",\n  \"stac_version\": \"1.1.0\",\n  \"id\": \"item-0\",\n  \"geometry\": {\n    \"type\": \"Point\",\n    \"coordinates\": [\n      -105.1019,\n      40.1672\n    ]\n  },\n  \"bbox\": [\n    -105.1019,\n    40.1672,\n    -105.1019,\n    40.1672\n  ],\n  \"properties\": {\n    \"datetime\": \"2024-01-01T00:00:00Z\"\n  },\n  \"links\": [],\n  \"assets\": {\n    \"data\": {\n      \"href\": \"https://storage.googleapis.com/open-cogs/stac-examples/20201211_223832_CS2.jpg\"\n    }\n  }\n}\n</pre> In\u00a0[70]: Copied! <pre>import time\n\nnew_items = [\n    create_item(\n        f\"new-item-{i}\",\n        datetime.datetime(1986, 6, 14, tzinfo=datetime.timezone.utc)\n        + datetime.timedelta(hours=i),\n        {\"foo\": \"bar\"},  # add a new attribute that wasn't in the original schema\n    )\n    for i in range(9999)\n]\n\nstart = time.time()\nold_items = await rustac.read(\"items.parquet\")\nprint(f\"That took {time.time() - start:0.2f} seconds to read\")\n\nstart = time.time()\nawait rustac.write(\"more-items.parquet\", old_items[\"features\"] + new_items)\nprint(f\"That took {time.time() - start:0.2f} seconds to write\")\n\nall_the_items = await rustac.read(\"more-items.parquet\")\nprint(\n    len(\n        list(item for item in all_the_items[\"features\"] if \"foo\" in item[\"properties\"])\n    ),\n    \"items have a 'foo' property\",\n)\n</pre> import time  new_items = [     create_item(         f\"new-item-{i}\",         datetime.datetime(1986, 6, 14, tzinfo=datetime.timezone.utc)         + datetime.timedelta(hours=i),         {\"foo\": \"bar\"},  # add a new attribute that wasn't in the original schema     )     for i in range(9999) ]  start = time.time() old_items = await rustac.read(\"items.parquet\") print(f\"That took {time.time() - start:0.2f} seconds to read\")  start = time.time() await rustac.write(\"more-items.parquet\", old_items[\"features\"] + new_items) print(f\"That took {time.time() - start:0.2f} seconds to write\")  all_the_items = await rustac.read(\"more-items.parquet\") print(     len(         list(item for item in all_the_items[\"features\"] if \"foo\" in item[\"properties\"])     ),     \"items have a 'foo' property\", ) <pre>That took 0.37 seconds to read\nThat took 1.20 seconds to write\n9999 items have a 'foo' property\n</pre> In\u00a0[71]: Copied! <pre>import duckdb\n\nawait rustac.write(\"new-items.parquet\", new_items)\nduckdb.sql(\n    \"select id, datetime, geometry from read_parquet(['items.parquet', 'new-items.parquet'])\"\n)\n</pre> import duckdb  await rustac.write(\"new-items.parquet\", new_items) duckdb.sql(     \"select id, datetime, geometry from read_parquet(['items.parquet', 'new-items.parquet'])\" ) Out[71]: <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    id     \u2502         datetime         \u2502         geometry          \u2502\n\u2502  varchar  \u2502 timestamp with time zone \u2502         geometry          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 item-0    \u2502 2023-12-31 17:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-1    \u2502 2023-12-31 18:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-2    \u2502 2023-12-31 19:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-3    \u2502 2023-12-31 20:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-4    \u2502 2023-12-31 21:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-5    \u2502 2023-12-31 22:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-6    \u2502 2023-12-31 23:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-7    \u2502 2024-01-01 00:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-8    \u2502 2024-01-01 01:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-9    \u2502 2024-01-01 02:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502   \u00b7       \u2502           \u00b7              \u2502             \u00b7             \u2502\n\u2502   \u00b7       \u2502           \u00b7              \u2502             \u00b7             \u2502\n\u2502   \u00b7       \u2502           \u00b7              \u2502             \u00b7             \u2502\n\u2502 item-9990 \u2502 2025-02-19 23:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-9991 \u2502 2025-02-20 00:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-9992 \u2502 2025-02-20 01:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-9993 \u2502 2025-02-20 02:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-9994 \u2502 2025-02-20 03:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-9995 \u2502 2025-02-20 04:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-9996 \u2502 2025-02-20 05:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-9997 \u2502 2025-02-20 06:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-9998 \u2502 2025-02-20 07:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u2502 item-9999 \u2502 2025-02-20 08:00:00-07   \u2502 POINT (-105.1019 40.1672) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ? rows (&gt;9999 rows, 20 shown)                          3 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518</pre> <p>Even though our old items don't have a <code>foo</code> property, we can still query on it with DuckDB by setting <code>union_by_name = true</code>.</p> In\u00a0[72]: Copied! <pre>duckdb.sql(\n    \"select count(*) from read_parquet(['items.parquet', 'new-items.parquet'], union_by_name = true) where foo = 'bar'\"\n)\n</pre> duckdb.sql(     \"select count(*) from read_parquet(['items.parquet', 'new-items.parquet'], union_by_name = true) where foo = 'bar'\" ) Out[72]: <pre>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 count_star() \u2502\n\u2502    int64     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         9999 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518</pre> <p>If we don't set <code>union_by_name = true</code>, we get an error because of the schema mismatch.</p> In\u00a0[73]: Copied! <pre>duckdb.sql(\"select id, foo from read_parquet(['items.parquet', 'new-items.parquet'])\")\n</pre> duckdb.sql(\"select id, foo from read_parquet(['items.parquet', 'new-items.parquet'])\") <pre>\n---------------------------------------------------------------------------\nBinderException                           Traceback (most recent call last)\nCell In[73], line 1\n----&gt; 1 duckdb.sql(\"select id, foo from read_parquet(['items.parquet', 'new-items.parquet'])\")\n\nBinderException: Binder Error: Referenced column \"foo\" not found in FROM clause!\nCandidate bindings: \"bbox\"</pre>"},{"location":"notebooks/stac-geoparquet/#stac-geoparquet","title":"stac-geoparquet\u00b6","text":"<p>stac-geoparquet is a data storage specification for STAC. There are (at least) two Python libraries for reading and writing stac-geoparquet:</p> <ul> <li>stac-geoparquet lives in the same repository as the specification</li> <li>Our rustac implementation does more of the hard work in Rust</li> </ul> <p>For more on the difference between the two implementations, see our README.</p>"},{"location":"notebooks/stac-geoparquet/#creating-stac-geoparquet","title":"Creating stac-geoparquet\u00b6","text":"<p>Create stac-geoparquet from an iterable of items.</p>"},{"location":"notebooks/stac-geoparquet/#appending","title":"Appending\u00b6","text":"<p>One of STAC's key features is its flexibility. The core specification is minimal, so data producers are encouraged to use extensions and custom attributes to add expressiveness to their STAC items. This flexibility is an awkward fit with parquet (and arrow), which require fixed schemas. Many parquet implementations simply punt on appends (e.g.).</p> <p>To add new data to an existing stac-geoparquet data store, you can:</p> <ul> <li>Read, update, and write</li> <li>Create a new file and search over both, e.g. with DuckDB</li> </ul> <p>Let's take a look at both options.</p>"},{"location":"notebooks/stac-geoparquet/#read-update-and-write","title":"Read, update, and write\u00b6","text":"<p>If you can fit all of your items into memory, you can read all of your items in, add the new items, then write them back out. rustac will take care of updating the output schema to match the new items. It's not very elegant, but it works.</p>"},{"location":"notebooks/stac-geoparquet/#create-a-new-file","title":"Create a new file\u00b6","text":"<p>Some tools, like DuckDB, can query across multiple parquet files. This lets you write your new items in a second file next to your old one, then query across both.</p>"},{"location":"notebooks/store/","title":"Using object storage","text":"In\u00a0[3]: Copied! <pre>import contextily\nimport pandas\nimport rustac\nfrom rustac.store import HTTPStore\nfrom geopandas import GeoDataFrame\n\nstore = HTTPStore(\n    \"https://raw.githubusercontent.com/stac-utils/rustac-py/refs/heads/main/data\"\n)\nitems = await rustac.read(\"100-sentinel-2-items.parquet\", store=store)\nprint(len(items[\"features\"]))\n\ndata_frame = GeoDataFrame.from_features(items)\ndata_frame[\"datetime\"] = pandas.to_datetime(data_frame[\"datetime\"])\naxis = data_frame.set_crs(epsg=4326).to_crs(epsg=3857).plot(alpha=0.5, edgecolor=\"k\")\ncontextily.add_basemap(axis, source=contextily.providers.CartoDB.Positron)\naxis.set_axis_off()\n</pre> import contextily import pandas import rustac from rustac.store import HTTPStore from geopandas import GeoDataFrame  store = HTTPStore(     \"https://raw.githubusercontent.com/stac-utils/rustac-py/refs/heads/main/data\" ) items = await rustac.read(\"100-sentinel-2-items.parquet\", store=store) print(len(items[\"features\"]))  data_frame = GeoDataFrame.from_features(items) data_frame[\"datetime\"] = pandas.to_datetime(data_frame[\"datetime\"]) axis = data_frame.set_crs(epsg=4326).to_crs(epsg=3857).plot(alpha=0.5, edgecolor=\"k\") contextily.add_basemap(axis, source=contextily.providers.CartoDB.Positron) axis.set_axis_off() <pre>100\n</pre> <p>There's a whole set of provided object storage backends. See https://developmentseed.org/obstore/latest/authentication/ for how you might configure authenticate with those backends.</p> In\u00a0[4]: Copied! <pre>from obstore.store import HTTPStore\n\nstore = HTTPStore(\n    \"https://raw.githubusercontent.com/stac-utils/rustac-py/refs/heads/main/data\"\n)\nitems = await rustac.read(\"100-sentinel-2-items.parquet\", store=store)\n</pre> from obstore.store import HTTPStore  store = HTTPStore(     \"https://raw.githubusercontent.com/stac-utils/rustac-py/refs/heads/main/data\" ) items = await rustac.read(\"100-sentinel-2-items.parquet\", store=store) <pre>/var/folders/yp/d6xvrkd943dgvqg5s9cpymc40000gn/T/ipykernel_65491/1946367820.py:4: RuntimeWarning: Successfully reconstructed a store defined in another Python module. Connection pooling will not be shared across store instances.\n  items = await rustac.read(\"100-sentinel-2-items.parquet\", store=store)\n</pre> <p>Notice how there's a warning? That's because we have to copy the <code>ObjectStore</code> when we pass it in to rustac. This means it can be a bit more efficient to use <code>rustac.store</code> if you're only working with rustac.</p>"},{"location":"notebooks/store/#using-object-storage","title":"Using object storage\u00b6","text":"<p>obstore is a new, powerful Python library for getting from and putting to object storage. rustac can use anything that implements <code>obstore.store.ObjectStore</code>, and also provides its own zero-dependency version in rustac.store.</p>"},{"location":"notebooks/store/#using-obstorestoreobjectstore","title":"Using obstore.store.ObjectStore.\u00b6","text":"<p>If you're doing work with obstore directly, you can re-use the same <code>ObjectStore</code>.</p>"}]}