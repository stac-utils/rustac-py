{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9555163a",
   "metadata": {},
   "source": [
    "# stac-geoparquet\n",
    "\n",
    "[stac-geoparquet](https://github.com/stac-utils/stac-geoparquet/blob/main/spec/stac-geoparquet-spec.md) is a data storage specification for STAC.\n",
    "There are (at least) two Python libraries for reading and writing **stac-geoparquet**:\n",
    "\n",
    "- [stac-geoparquet](https://pypi.org/project/stac-geoparquet/) lives in the same repository as the specification\n",
    "- Our **rustac** implementation does more of the hard work in Rust\n",
    "\n",
    "For more on the difference between the two implementations, see [our README](https://github.com/stac-utils/rustac-py?tab=readme-ov-file#stac-geoparquet).\n",
    "\n",
    "## Creating stac-geoparquet\n",
    "\n",
    "Create **stac-geoparquet** from an iterable of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37025933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.0 kB\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import os\n",
    "import datetime\n",
    "import humanize\n",
    "import rustac\n",
    "\n",
    "\n",
    "def create_item(\n",
    "    id: str, dt: datetime.datetime, extra_properties: dict[str, Any] | None = None\n",
    ") -> dict[str, Any]:\n",
    "    properties = {\n",
    "        \"datetime\": dt.isoformat(),\n",
    "    }\n",
    "    if extra_properties:\n",
    "        properties.update(extra_properties)\n",
    "    return {\n",
    "        \"type\": \"Feature\",\n",
    "        \"stac_version\": \"1.1.0\",\n",
    "        \"id\": id,\n",
    "        \"geometry\": {\"type\": \"Point\", \"coordinates\": [-105.1019, 40.1672]},\n",
    "        \"bbox\": [-105.1019, 40.1672, -105.1019, 40.1672],\n",
    "        \"properties\": properties,\n",
    "        # Assets can't be empty at the moment: https://github.com/stac-utils/rustac/issues/766\n",
    "        \"assets\": {\n",
    "            \"data\": {\n",
    "                \"href\": \"https://storage.googleapis.com/open-cogs/stac-examples/20201211_223832_CS2.jpg\"\n",
    "            }\n",
    "        },\n",
    "        \"links\": [],\n",
    "    }\n",
    "\n",
    "\n",
    "items = [\n",
    "    create_item(\n",
    "        f\"item-{i}\",\n",
    "        datetime.datetime(2024, 1, 1, tzinfo=datetime.timezone.utc)\n",
    "        + datetime.timedelta(hours=i),\n",
    "    )\n",
    "    for i in range(10000)\n",
    "]\n",
    "await rustac.write(\"items.parquet\", items)\n",
    "print(humanize.naturalsize(os.path.getsize(\"items.parquet\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d11b3",
   "metadata": {},
   "source": [
    "Reading is just as simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "164ecaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"Feature\",\n",
      "  \"stac_version\": \"1.1.0\",\n",
      "  \"id\": \"item-0\",\n",
      "  \"geometry\": {\n",
      "    \"type\": \"Point\",\n",
      "    \"coordinates\": [\n",
      "      -105.1019,\n",
      "      40.1672\n",
      "    ]\n",
      "  },\n",
      "  \"bbox\": [\n",
      "    -105.1019,\n",
      "    40.1672,\n",
      "    -105.1019,\n",
      "    40.1672\n",
      "  ],\n",
      "  \"properties\": {\n",
      "    \"datetime\": \"2024-01-01T00:00:00Z\"\n",
      "  },\n",
      "  \"links\": [],\n",
      "  \"assets\": {\n",
      "    \"data\": {\n",
      "      \"href\": \"https://storage.googleapis.com/open-cogs/stac-examples/20201211_223832_CS2.jpg\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "item_collection = await rustac.read(\"items.parquet\")\n",
    "print(json.dumps(item_collection[\"features\"][0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325e2af",
   "metadata": {},
   "source": [
    "### Writing in chunks\n",
    "\n",
    "If you have a lot of items, you might not want to load them all into memory at once.\n",
    "We provide a context manager for iteratively writing **stac-geoparquet**.\n",
    "This example is a bit contrived, but you get the idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9045b4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 499 items\n",
      "Writing batch of 20 items\n",
      "Read back 10000 items\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "iterator = itertools.batched(items, 499)\n",
    "\n",
    "with rustac.geoparquet_writer(list(next(iterator)), \"items-batched.parquet\") as writer:\n",
    "    for item_batch in iterator:\n",
    "        print(f\"Writing batch of {len(item_batch)} items\")\n",
    "        writer.write(list(item_batch))\n",
    "\n",
    "\n",
    "item_collection = await rustac.read(\"items-batched.parquet\")\n",
    "print(\"Read back\", len(item_collection[\"features\"]), \"items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223d4ce",
   "metadata": {},
   "source": [
    "## Appending\n",
    "\n",
    "One of STAC's key features is its flexibility.\n",
    "The core specification is minimal, so data producers are encouraged to use [extensions](https://stac-extensions.github.io/) and custom attributes to add expressiveness to their STAC items. \n",
    "This flexibility is an awkward fit with [parquet](https://parquet.apache.org/) (and [arrow](https://arrow.apache.org/)), which require fixed schemas.\n",
    "Many parquet implementations simply punt on appends ([e.g.](https://github.com/apache/arrow/issues/42711#issuecomment-2184210686)).\n",
    "\n",
    "To add new data to an existing **stac-geoparquet** data store, you can:\n",
    "\n",
    "- Read, update, and write\n",
    "- Create a new file and search over both, e.g. with [DuckDB](https://duckdb.org/)\n",
    "\n",
    "Let's take a look at both options.\n",
    "\n",
    "### Read, update, and write\n",
    "\n",
    "If you can fit all of your items into memory, you can read all of your items in, add the new items, then write them back out.\n",
    "**rustac** will take care of updating the output schema to match the new items.\n",
    "It's not very elegant, but it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870cbebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That took 0.08 seconds to read\n",
      "That took 0.28 seconds to write\n",
      "9999 items have a 'foo' property\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "new_items = [\n",
    "    create_item(\n",
    "        f\"new-item-{i}\",\n",
    "        datetime.datetime(1986, 6, 14, tzinfo=datetime.timezone.utc)\n",
    "        + datetime.timedelta(hours=i),\n",
    "        {\"foo\": \"bar\"},  # add a new attribute that wasn't in the original schema\n",
    "    )\n",
    "    for i in range(9999)\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "old_items = await rustac.read(\"items.parquet\")\n",
    "print(f\"That took {time.time() - start:0.2f} seconds to read\")\n",
    "\n",
    "start = time.time()\n",
    "await rustac.write(\"more-items.parquet\", old_items[\"features\"] + new_items)\n",
    "print(f\"That took {time.time() - start:0.2f} seconds to write\")\n",
    "\n",
    "all_the_items = await rustac.read(\"more-items.parquet\")\n",
    "print(\n",
    "    len(\n",
    "        list(item for item in all_the_items[\"features\"] if \"foo\" in item[\"properties\"])\n",
    "    ),\n",
    "    \"items have a 'foo' property\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afaf71c",
   "metadata": {},
   "source": [
    "### Create a new file\n",
    "\n",
    "Some tools, like **DuckDB**, can query across multiple parquet files.\n",
    "This lets you write your new items in a second file next to your old one, then query across both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fabaa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────┬──────────────────────────┬────────────────────────────────────────────────────────────────────┐\n",
       "│    id     │         datetime         │                              geometry                              │\n",
       "│  varchar  │ timestamp with time zone │                                blob                                │\n",
       "├───────────┼──────────────────────────┼────────────────────────────────────────────────────────────────────┤\n",
       "│ item-0    │ 2023-12-31 17:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-1    │ 2023-12-31 18:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-2    │ 2023-12-31 19:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-3    │ 2023-12-31 20:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-4    │ 2023-12-31 21:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-5    │ 2023-12-31 22:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-6    │ 2023-12-31 23:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-7    │ 2024-01-01 00:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-8    │ 2024-01-01 01:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-9    │ 2024-01-01 02:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│   ·       │           ·              │                                 ·                                  │\n",
       "│   ·       │           ·              │                                 ·                                  │\n",
       "│   ·       │           ·              │                                 ·                                  │\n",
       "│ item-9990 │ 2025-02-19 23:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-9991 │ 2025-02-20 00:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-9992 │ 2025-02-20 01:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-9993 │ 2025-02-20 02:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-9994 │ 2025-02-20 03:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-9995 │ 2025-02-20 04:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-9996 │ 2025-02-20 05:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-9997 │ 2025-02-20 06:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-9998 │ 2025-02-20 07:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "│ item-9999 │ 2025-02-20 08:00:00-07   │ \\x01\\x01\\x00\\x00\\x00\\x98\\xDD\\x93\\x87\\x85FZ\\xC0\\x13\\xF2A\\xCFf\\x15D@ │\n",
       "├───────────┴──────────────────────────┴────────────────────────────────────────────────────────────────────┤\n",
       "│ ? rows (>9999 rows, 20 shown)                                                                   3 columns │\n",
       "└───────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "await rustac.write(\"new-items.parquet\", new_items)\n",
    "duckdb.sql(\n",
    "    \"select id, datetime, geometry from read_parquet(['items.parquet', 'new-items.parquet'])\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb22d3",
   "metadata": {},
   "source": [
    "Even though our old items don't have a `foo` property, we can still query on it with DuckDB by setting `union_by_name = true`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01c0ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────┐\n",
       "│ count_star() │\n",
       "│    int64     │\n",
       "├──────────────┤\n",
       "│         9999 │\n",
       "└──────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\n",
    "    \"select count(*) from read_parquet(['items.parquet', 'new-items.parquet'], union_by_name = true) where foo = 'bar'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c6fd88",
   "metadata": {},
   "source": [
    "If we don't set `union_by_name = true`, we get an error because of the schema mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18bc3a4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "BinderException",
     "evalue": "Binder Error: Referenced column \"foo\" not found in FROM clause!\nCandidate bindings: \"bbox\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBinderException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mduckdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mselect id, foo from read_parquet([\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mitems.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnew-items.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m])\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mBinderException\u001b[39m: Binder Error: Referenced column \"foo\" not found in FROM clause!\nCandidate bindings: \"bbox\""
     ]
    }
   ],
   "source": [
    "duckdb.sql(\"select id, foo from read_parquet(['items.parquet', 'new-items.parquet'])\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rustac-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
